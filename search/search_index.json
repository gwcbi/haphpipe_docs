{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About HAPHPIPE HA plotype and PH ylodynamics pipeline for viral assembly, population genetics, and phylodynamics. We assume basic familiarity with conda environments, basic bash knowledge and knowledge of general next-generation sequencing (NGS) concepts. For more information regarding all of these, see helpful links and FAQ. (insert links to markdown pages once these are split up) Remember that a directory is a simply a folder nesting system, similar to what you see on your computer. Where you see \"folder\" below you can also say \"directory.\" HAPHPIPE is intended only for Linux and Mac OS X platforms. This User Guide was developed by undergrads and graduate students to be accessible for users at all stages. Maggie Steiner, Keylie M Gibson, Matthew L Bendall, and Uzma Rentia all contributed to developing this User Guide and testing HAPHPIPE. See paper for more information and paper for validation study. Citing HAPHPIPE When using HAPHPIPE, please cite our article when it is available. For now, reference the GitHub website: https://github.com/gwcbi/haphpipe The HAPHPIPE suite Each stage can be run on its own. Stages are grouped into 4 categories: hp_reads , hp_assemble , hp_haplotype , and hp_annotate . More detailed description of command line options for each stage are available in the below sections. To view all available stages in HAPHPIPE, run: haphpipe -h Output will look like: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data HAPHPIPE consists of a suite of sub-commands under each stage that are invoked as follows: haphpipe [stage] [sub-command] [options] For example, to join paired end reads, one would invoke the following: haphpipe join_reads --fq1 trimmed_1.fastq --fq2 trimmed_2.fastq","title":"Home"},{"location":"#about-haphpipe","text":"HA plotype and PH ylodynamics pipeline for viral assembly, population genetics, and phylodynamics. We assume basic familiarity with conda environments, basic bash knowledge and knowledge of general next-generation sequencing (NGS) concepts. For more information regarding all of these, see helpful links and FAQ. (insert links to markdown pages once these are split up) Remember that a directory is a simply a folder nesting system, similar to what you see on your computer. Where you see \"folder\" below you can also say \"directory.\" HAPHPIPE is intended only for Linux and Mac OS X platforms. This User Guide was developed by undergrads and graduate students to be accessible for users at all stages. Maggie Steiner, Keylie M Gibson, Matthew L Bendall, and Uzma Rentia all contributed to developing this User Guide and testing HAPHPIPE. See paper for more information and paper for validation study.","title":"About HAPHPIPE"},{"location":"#citing-haphpipe","text":"When using HAPHPIPE, please cite our article when it is available. For now, reference the GitHub website: https://github.com/gwcbi/haphpipe","title":"Citing HAPHPIPE"},{"location":"#the-haphpipe-suite","text":"Each stage can be run on its own. Stages are grouped into 4 categories: hp_reads , hp_assemble , hp_haplotype , and hp_annotate . More detailed description of command line options for each stage are available in the below sections. To view all available stages in HAPHPIPE, run: haphpipe -h Output will look like: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data HAPHPIPE consists of a suite of sub-commands under each stage that are invoked as follows: haphpipe [stage] [sub-command] [options] For example, to join paired end reads, one would invoke the following: haphpipe join_reads --fq1 trimmed_1.fastq --fq2 trimmed_2.fastq","title":"The HAPHPIPE suite"},{"location":"adv/","text":"Making your own pipelines with Bash","title":"Advanced Users"},{"location":"adv/#making-your-own-pipelines-with-bash","text":"","title":"Making your own pipelines with Bash"},{"location":"demos/","text":"Data for both demos is included in the repository. Both samples should run quickly (less than five minutes using eight CPUs). Note: ensure PredictHaplo is installed prior to running the demos . Demo01 We provide a subsample of reads for this sample. We obtained this sample using fastq-dump . fastq-dump --origfmt --defline-qual + --split-files --accession SRR8525886 condo activate haphpipe hp_sample_reads --fq1 SRR8525886_1.fastq --fq2 SRR8525886_2.fastq --nreads 10000 Demo01 uses real HIV-1 data (SRA: SAMN10820316 ). This demo runs both the haphpipe_assemble_01 de novo assembly and haphpipe_assemble_02 amplicon assembly pipelines (see here for details). Then, the final output of each pipeline ( final.fna ) is run through the haplotype stages (see here for details). To run, activate your HAPHPIPE environment and execute the following code: code block here After running, you should see the following output files: final.fna final.vcf.gz final.bam # For all three amplicons: ph_summary.txt ph_haplotypes.fna Demo02 Demo02 uses a mixture of three HIV-1 subtype B references (Genbank: AY795905 , KP411829 , MF373129 ) in a ratio of 60%, 30%, and 10%, respectively. The provided FASTA file contains the protease and reverse transcriptase gene regions. This demo runs the hp_assemble_01 de novo assembly pipeline (see here for details) and uses the final output ( final.fna ) as input for the haplotype stages (see here for details). To run, activate your HAPHPIPE environment and execute the following code: code block here The output for demo02 includes three 1,617bp reconstructed haplotypes and a haplotype diversity estimate of 0.5481. After running, you should see the following output files: final.fna final.vcf.gz final.bam ph_summary.txt ph_haplotypes.fna","title":"Demos"},{"location":"demos/#demo01","text":"We provide a subsample of reads for this sample. We obtained this sample using fastq-dump . fastq-dump --origfmt --defline-qual + --split-files --accession SRR8525886 condo activate haphpipe hp_sample_reads --fq1 SRR8525886_1.fastq --fq2 SRR8525886_2.fastq --nreads 10000 Demo01 uses real HIV-1 data (SRA: SAMN10820316 ). This demo runs both the haphpipe_assemble_01 de novo assembly and haphpipe_assemble_02 amplicon assembly pipelines (see here for details). Then, the final output of each pipeline ( final.fna ) is run through the haplotype stages (see here for details). To run, activate your HAPHPIPE environment and execute the following code: code block here After running, you should see the following output files: final.fna final.vcf.gz final.bam # For all three amplicons: ph_summary.txt ph_haplotypes.fna","title":"Demo01"},{"location":"demos/#demo02","text":"Demo02 uses a mixture of three HIV-1 subtype B references (Genbank: AY795905 , KP411829 , MF373129 ) in a ratio of 60%, 30%, and 10%, respectively. The provided FASTA file contains the protease and reverse transcriptase gene regions. This demo runs the hp_assemble_01 de novo assembly pipeline (see here for details) and uses the final output ( final.fna ) as input for the haplotype stages (see here for details). To run, activate your HAPHPIPE environment and execute the following code: code block here The output for demo02 includes three 1,617bp reconstructed haplotypes and a haplotype diversity estimate of 0.5481. After running, you should see the following output files: final.fna final.vcf.gz final.bam ph_summary.txt ph_haplotypes.fna","title":"Demo02"},{"location":"expipes/","text":"The example pipelines are written in bash scripting language. The reference files used in both examples are included in the demo data. To run in haphpipe, execute one of the following lines: haphpipe_assemble_01 read1.fq.gz read2.fq.gz ../refs/HIV_B.K03455.HXB2.fasta ../refs/HIV_B.K03455.HXB2.gtf sampleID haphpipe_assemble_02 read1.fq.gz read2.fq.gz ../refs/HIV_B.K03455.HXB2.amplicons.fasta sampleID Pipeline 1 implements amplicon assembly using a de novo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Pipeline 2 implements amplicon assembly using a reference-based mapping approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Pipeline 1: haphpipe_assemble_01 This pipeline implements de novo assembly. Reads are first trimmed ( trim_reads ) and used as input for denovo assembly ( assemble_denovo ). The de novo assembly stage automatically performs error correction on the trimmed reads. The assembled contigs are used as input for amplicon assembly ( assemble_amplicons ) along with reference FASTA and GTF files. The assembly is then iteratively refined up to five times ( refine_assembly ) by mapping corrected reads to the assembled FASTA file and lastly finalized ( finalize_assembly ), resulting in a FASTA file with final consensus sequences, final VCF, and aligned BAM file. To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_01 -h , and it will show the output: USAGE: haphpipe_assemble_01 [read1] [read2] [reference_fasta] [reference_gtf] [samp_id] outdir ----- HAPHPIPE assembly pipeline 01 ----- This pipeline implements amplicon assembly using a denovo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) reference_fasta: Reference sequence (fasta) reference_gtf: Amplicon regions (GTF) samp_id: Sample ID outdir: Output directory (default is [sample_dir]/haphpipe_assemble_01) General command to execute pipeline 1: haphpipe_assemble_01 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta refs/ref.gtf samp Example command to run with demo01: insert Pipeline 2: haphpipe_assemble_02 This pipeline implements reference-based mapping assembly. Reads are first trimmed ( trim_reads ) and error-corrected ( ec_reads ). The corrected reads are used as input for reference-based mapping assembly ( refine_assembly ) for up to five iterations. Lastly, the assembly is finalized ( finalize_assembly ) by mapping reads onto the refined reference sequence. The final output is a FASTA file with final consensus sequences, final VCF, and aligned BAM file. (insert Figure 2 here) To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_02 -h , and it will show the output: USAGE: haphpipe_assemble_02 [read1] [read2] [amplicons_fasta] [samp_id] outdir ----- HAPHPIPE assembly pipeline 02 ----- This pipeline implements amplicon assembly using a reference-based approach. Reads are error-corrected and aligned to provided amplicon reference with up to five refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) amplicons_fasta: Amplicon reference sequence (fasta) samp_id: Sample ID outdir: Output directory (default is sample_dir/haphpipe_assemble_02) General command to execute pipeline 1: haphpipe_assemble_02 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta samp Example command to run with demo01: insert","title":"Example Pipelines"},{"location":"expipes/#pipeline-1-haphpipe_assemble_01","text":"This pipeline implements de novo assembly. Reads are first trimmed ( trim_reads ) and used as input for denovo assembly ( assemble_denovo ). The de novo assembly stage automatically performs error correction on the trimmed reads. The assembled contigs are used as input for amplicon assembly ( assemble_amplicons ) along with reference FASTA and GTF files. The assembly is then iteratively refined up to five times ( refine_assembly ) by mapping corrected reads to the assembled FASTA file and lastly finalized ( finalize_assembly ), resulting in a FASTA file with final consensus sequences, final VCF, and aligned BAM file. To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_01 -h , and it will show the output: USAGE: haphpipe_assemble_01 [read1] [read2] [reference_fasta] [reference_gtf] [samp_id] outdir ----- HAPHPIPE assembly pipeline 01 ----- This pipeline implements amplicon assembly using a denovo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) reference_fasta: Reference sequence (fasta) reference_gtf: Amplicon regions (GTF) samp_id: Sample ID outdir: Output directory (default is [sample_dir]/haphpipe_assemble_01) General command to execute pipeline 1: haphpipe_assemble_01 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta refs/ref.gtf samp Example command to run with demo01: insert","title":"Pipeline 1: haphpipe_assemble_01"},{"location":"expipes/#pipeline-2-haphpipe_assemble_02","text":"This pipeline implements reference-based mapping assembly. Reads are first trimmed ( trim_reads ) and error-corrected ( ec_reads ). The corrected reads are used as input for reference-based mapping assembly ( refine_assembly ) for up to five iterations. Lastly, the assembly is finalized ( finalize_assembly ) by mapping reads onto the refined reference sequence. The final output is a FASTA file with final consensus sequences, final VCF, and aligned BAM file. (insert Figure 2 here) To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_02 -h , and it will show the output: USAGE: haphpipe_assemble_02 [read1] [read2] [amplicons_fasta] [samp_id] outdir ----- HAPHPIPE assembly pipeline 02 ----- This pipeline implements amplicon assembly using a reference-based approach. Reads are error-corrected and aligned to provided amplicon reference with up to five refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) amplicons_fasta: Amplicon reference sequence (fasta) samp_id: Sample ID outdir: Output directory (default is sample_dir/haphpipe_assemble_02) General command to execute pipeline 1: haphpipe_assemble_02 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta samp Example command to run with demo01: insert","title":"Pipeline 2: haphpipe_assemble_02"},{"location":"faq/","text":"HAPHPIPE NGS Using the Command Line Conda Bash","title":"FAQ"},{"location":"faq/#haphpipe","text":"","title":"HAPHPIPE"},{"location":"faq/#ngs","text":"","title":"NGS"},{"location":"faq/#using-the-command-line","text":"","title":"Using the Command Line"},{"location":"faq/#conda","text":"","title":"Conda"},{"location":"faq/#bash","text":"","title":"Bash"},{"location":"haphpipe_userguide/","text":"Haphpipe User Guide HA plotype and PH ylodynamics pipeline for viral assembly, population genetics, and phylodynamics. We assume basic familiarity with conda environments, basic bash knowledge and knowledge of general next-generation sequencing (NGS) concepts. For more information regarding all of these, see helpful links and FAQ. (insert links to markdown pages once these are split up) Remember that a directory is a simply a folder nesting system, similar to what you see on your computer. Where you see \"folder\" below you can also say \"directory.\" HAPHPIPE is intended only for Linux and Mac OS X platforms. This User Guide was developed by undergrads and graduate students to be accessible for users at all stages. Maggie Steiner, Keylie M Gibson, Matthew L Bendall, .... all contributed to developing this User Guide and testing HAPHPIPE. See paper for more information and paper for validation study. Citing HAPHPIPE: insert eventually I want each of these a separate document, for now I'll just make a giant one. Installation For now, the installation goes like this. We are hoping to make it into a stand alone bioconda recipe soon. HAPHIPE depends on more than a dozen different programs, each of which may itself depend on other programs and libraries. Installing everything separately would be a nightmare, so you should use the package manager \"Bioconda\" to install everything. Bioconda is a popular package manager in the bioinformatics world. See helpful links for more information and resources for Bioconda. This User Guide describes where to get Bioconda and how to install it, then how to use Bioconda to install the necessary programs for HAPHPIPE. This User Guide details the acquisition and installation of one program, GTAK, that is not handled by Bioconda, and finally the acquisition and installation of HAPHPIPE itself. Here, we describe the procedure for installing HAPHPIPE using the package manager Bioconda (Gr\u00fcning et al. 2018) on the command line. If you are unfamiliar with Bioconda, please see https://bioconda.github.io for installation and channel setup. HAPHPIPE is available at https://github.com/gwcbi/haphpipe and is written in Python 3.7.2 coding language. An online documentation is available at https://github.com/gwcbi/haphpipe/wiki. The installation process begins with the creation of a conda environment that installs the necessary dependencies required by HAPHPIPE. Once the conda environment has been created, it can be activated for use with the command conda activate haphpipe. Due to license restrictions, Bioconda cannot distribute and install GATK (McKenna et al. 2010; Van der Auwera et al. 2013; Poplin et al. 2018) directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute (https://software.broadinstitute.org/gatk/download/archive). You can then install HAPHPIPE using the single command pip install git+git://github.com/gwcbi/haphpipe.git, which pulls the repository from Github. 1. Install conda Download the conda package: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh 2. Set up conda channels These need to be put in as a command in the order they come, as this sets the priority for where packages are pulled from. Therefore, in this order, conda-forge is top priority and explored first when downloading a program. conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge 3. Create a conda environment with the following dependencies conda create -n haphpipe \\ python \\ future \\ pyyaml \\ biopython \\ seqtk \\ bowtie2 \\ bwa \\ flash \\ freebayes \\ mummer \\ picard \\ trimmomatic \\ samtools=1.9 \\ gatk=3.8 \\ spades \\ blast \\ sierrapy 4. Activate the environment conda activate haphpipe 5. Install GATK GATK can be dowloaded before or after creating the haphpipe conda environment, but it must be registered after creating the conda environment. Due to license restrictions, bioconda cannot distribute and install GATK directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute: https://software.broadinstitute.org/gatk/download/archive . Once you download a copy, register the package using gatk3-register : gatk3-register /path/to/GenomeAnalysisTK-3.8-0-ge9d806836.tar.bz2 This will copy GATK into your conda environment. NOTE: HAPHPIPE was developed and tested using GATK 3.8. 6. Install HAPHPIPE pip install git+git://github.com/gwcbi/haphpipe.git Upon completion of the installation, you can test it to ensure the repository has been installed completely and correctly by running haphpipe -h (in quick start). Once HAPHPIPE is installed and performing correctly, there is no need to install it again; simply activate the conda environment when needed by executing conda activate haphpipe . If a new version is released in the future, HAPHPIPE can be updated by running the command line pip install --upgrade git+git://github.com/gwcbi/haphpipe.git . At any point, the -h option that follows any HAPHPIPE stage will output a help message that provides a description of the stage and the desired input(s) and output(s). 7. Installing PredictHaplo The user is required to install PredictHaplo on their own, as there are system-dependent variables within the installation process. We were unable to successfully incorporate PredictHaplo into HAPHPIPE so this step was unnecessary for you to install. Users are required to download PredictHaplo on their own computing system prior to running any of the haplotype stages ( hp_predict_haplo and hp_ph_parser ). Here is how the GW CBI team installed PredictHaplo onto our HPC, which has a slurm scheduling system and uses Lua module files. We cannot help with the installation of this software, but have provided the code that we used here to install PredictHaplo onto our system. Please see their website for contact information if you need help installing their program. You can download the new version for paired-end reads of the PredictHaplo program from their website . The instructions are in the README in the folder downloaded. We have also provided them here for your access. provide the readme file for them This module loads predicthaplo onto GWU's HPC - Colonial One. See https://bmda.dmi.unibas.ch/software.html cd /path/to/modules/predicthaplo # use gcc 4.9.4, add blas and lapack to library path module load gcc/4.9.4 module load blas/gcc/64 module load lapack/gcc/64 # download source cd archive wget https://bmda.dmi.unibas.ch/software/PredictHaplo-Paired-0.4.tgz cd .. # unzip source and change directory name tar xfvz archive/PredictHaplo-Paired-0.4.tgz mv PredictHaplo-Paired-0.4 0.4 cd 0.4 # install scythestat tar xfvz scythestat-1.0.3.tar.gz cd scythestat-1.0.3 ./configure --prefix=/path/to/modules/predicthaplo/0.4/NEWSCYTHE make install cd .. # compile predicthaplo make If a segfault error occurs during the hp_predict_haplo stage, this is not a characteristic of HAPHPIPE but rather that of PredictHaplo. Sometimes, we have luck if we just rerun the code again or move to an interactive CPU node. We are unsure what causes this error, and we only see it between the local and global reconstruction phases in PredictHaplo. --- Quick start Activate HAPHPIPE 1. Activate haphpipe Make sure you have conda running. For students at GW using Colonial One, you need to load the miniconda3 module like such prior to activating the haphpipe conda environemnt: module load miniconda3 . conda activate haphpipe 2. Test that it is loaded correctly haphpipe -h should produce: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data Demo Demo1, de novo assembly, tell them exactly what fastq read files they need to download, exactly where to find those files, and exactly where to download them. Provide URLs and what to expect to see in the SRL archives. These are beginners, they don't know how to find anything. Then tell them that Demo2 you will lead them through a reference guided assembly and that they will need to download the following finished genomes sequences and exactly where to get them We will now go over two ways to complete these demos: (i) automatically, which is to ultimately test if HAPHPIPE has been installed correctly and (ii) interactively, to get a feel and experience running HAPHPIPE yourself. Data for both demos is included in the repository. Both samples should run quickly (less than five minutes using eight CPUs). Note: ensure PredictHaplo is installed prior to running the demos. Automatically to test the installation of HAPHPIPE insert the code to run the demo data Interactively to familiarize yourself with running HAPHPIPE Example pipelines The example pipelines are written in bash scripting language. The reference files used in both examples are included in the demo data. To run in haphpipe, execute one of the following lines: Pipeline 1 implements amplicon assembly using a de novo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Pipeline 2 implements amplicon assembly using a reference-based mapping approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Pipeline 1: haphpipe_assemble_01 This pipeline implements de novo assembly. Reads are first trimmed ( trim_reads ) and used as input for denovo assembly ( assemble_denovo ). The de novo assembly stage automatically performs error correction on the trimmed reads. The assembled contigs are used as input for amplicon assembly ( assemble_amplicons ) along with reference FASTA and GTF files. The assembly is then iteratively refined up to five times ( refine_assembly ) by mapping corrected reads to the assembled FASTA file and lastly finalized ( finalize_assembly ), resulting in a FASTA file with final consensus sequences, final VCF, and aligned BAM file. To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_01 -h , and it will show the output: USAGE: haphpipe_assemble_01 [read1] [read2] [reference_fasta] [reference_gtf] [samp_id] outdir ----- HAPHPIPE assembly pipeline 01 ----- This pipeline implements amplicon assembly using a denovo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) reference_fasta: Reference sequence (fasta) reference_gtf: Amplicon regions (GTF) samp_id: Sample ID outdir: Output directory (default is [sample_dir]/haphpipe_assemble_01) General command to execute pipeline 1: haphpipe_assemble_01 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta refs/ref.gtf samp Example command to run with demo01: insert Pipeline 2: haphpipe_assemble_02 This pipeline implements reference-based mapping assembly. Reads are first trimmed ( trim_reads ) and error-corrected ( ec_reads ). The corrected reads are used as input for reference-based mapping assembly ( refine_assembly ) for up to five iterations. Lastly, the assembly is finalized ( finalize_assembly ) by mapping reads onto the refined reference sequence. The final output is a FASTA file with final consensus sequences, final VCF, and aligned BAM file. (insert Figure 2 here) To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_02 -h , and it will show the output: USAGE: haphpipe_assemble_02 [read1] [read2] [amplicons_fasta] [samp_id] outdir ----- HAPHPIPE assembly pipeline 02 ----- This pipeline implements amplicon assembly using a reference-based approach. Reads are error-corrected and aligned to provided amplicon reference with up to five refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) amplicons_fasta: Amplicon reference sequence (fasta) samp_id: Sample ID outdir: Output directory (default is sample_dir/haphpipe_assemble_02) General command to execute pipeline 1: haphpipe_assemble_02 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta samp Example command to run with demo01: insert --- HAPHPIPE suite Each stage can be run on its own. Stages are grouped into 4 categories: hp_reads , hp_assemble , hp_haplotype , and hp_annotate . More detailed description of command line options for each stage are available in the wiki . To view all available stages in HAPHPIPE, run: haphpipe -h Output will look like: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data HAPHPIPE consists of a suite of sub-commands under each stage that are invoked as follows: haphpipe [stage] [sub-command] [options] For example, to join paired end reads, one would invoke the following: haphpipe join_reads --fq1 trimmed_1.fastq --fq2 trimmed_2.fastq I want all stages to have a table like this detailing the options like this. hp_reads hp_reads involves cleaning up the raw read sequences, as well as other processing steps. Modules to manipulate reads. sample_reads Subsample reads using seqtk ( documentation ). Input is reads in FASTQ format. Output is sampled reads in FASTQ format. You do not have to have all read options (i.e., read1, read2 AND unpaired reads). You can have a combination of any of those. Usage and option summary Usage: haphpipe sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage This pulls 1000 reads from these paired end files with a starting seed of 1234. haphpipe sample_reads --fq1 read_1.fastq --fq2 read_2.fastq --nreads 1000 --seed 1234 -- trim_reads Trim reads using Trimmomatic ( documentation ). Input is reads in FASTQ format. Output is trimmed reads in FASTQ format. Usage and option summary Usage: haphpipe trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage This trims paired end read files 1 and 2. haphpipe trim_reads --fq1 read_1.fastq --fq2 read_2.fastq -- join_reads Join reads using FLASH ( paper ). Input is reads in FASTQ format. Output is joined reads in FASTQ format. Usage and option summary Usage: haphpipe join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] (or): hp_join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage -- ec_reads Error correction using SPAdes ( documentation ). Input is reads in FASTQ format. Output is error-corrected reads in FASTQ format. Remember that HAPHPIPE is intended for Illumina reads, therefore the error correction is based on Illumina sequencing errors. Usage and option summary Usage: haphpipe ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage -- hp_assemble Assemble consensus sequence(s). Input reads (in FASTQ format) are assembled using either denovo assembly or reference-based alignment. Resulting consensus can be further refined. assemble_denovo Assemble reads via de novo assembly using SPAdes ( documentation ). Input is reads in FASTQ format. Output is contigs in FNA format. Usage and option summary Usage: haphpipe assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage assemble_amplicons Assemble contigs from de novo assembly using both a reference sequence and amplicon regions with MUMMER 3+ ( documentation ). Input is contigs and reference sequence in FASTA format and amplicon regions in GTF format. Usage and option summary Usage: haphpipe assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage assemble_scaffold Scaffold contigs against a reference sequence with MUMMER 3+ ( documentation ). Input is contigs in FASTA format and reference sequence in FASTA format. Output is scaffold assembly, alligned scaffold, imputed scaffold, and padded scaffold in FASTA format. Usage and option summary Usage: haphpipe assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] (or): hp_assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage align_reads Map reads to reference sequence (instead of running de novo assembly) using Bowtie2 ( documentation ) and Picard ( documentation ). Input is reads in FASTQ format and reference sequence in FASTA format. Usage and option summary Usage: haphpipe align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage call_variants Variant calling from alignment using GATK ( documentation ). Input is alignment file in BAM format and reference sequence in FASTA format (either reference from reference-based assembly or consensus final sequence from de novo assembly). Output is a Variant Call File (VCF) format file. Usage and option summary Usage: haphpipe call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] (or): hp_call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage vcf_to_consensus Generate a consensus sequence from a VCF file. Input is a VCF file. Output is the consensus sequence in FASTA format. Usage and option summary Usage: haphpipe vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] (or): hp_vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage refine_assembly Map reads to a denovo assembly or reference alignment. Assembly or alignment is iteratively updated. Input is reads in FASTQ format and reference sequence (assembly or reference alignment) in FASTA format. Output is refined assembly in FASTA format. Usage and option summary Usage: haphpipe refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage finalize_assembly Finalize consensus, map reads to consensus, and call variants. Input is reads in FASTQ format and reference sequence in FASTA format. Output is finalized reference sequence, alignment, and variants (in FASTA, BAM, and VCF formats, respectively). Usage and option summary Usage: haphpipe finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage hp_haplotype Haplotype assembly stages. HAPHPIPE implements PredictHaplo ( paper ), although other haplotype reconstruction programs can be utilized outside of HAPHPIPE using the final output of HAPHPIPE, typically with the final consensus sequence (FASTA) file, reads (raw, trimmed, and/or corrected), and/or final alignment (BAM) file as input. predict_haplo Haplotype identification with PredictHaplo. Input is reads in FASTQ format and and reference sequence in FASTA format. Output is the longest global haplotype file and corresponding HTML file. Note: PredictHaplo must be installed separately before running this stage. Usage and option summary Usage: haphpipe predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] (or): hp_ predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] Output files: best.fa Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --ref_fa Reference sequence used to align reads (Fasta). --interval_txt File with intervals to perform haplotype reconstruction. --outdir Output directory (default: current directory). Options: Option Description --min_readlength Minimum read length passed to PredictHaplo (default: 36). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage ph_parser Returns PredictHaplo output as a correctly formatted FASTA file. Input is the output file from predict_haplo (longest global .fas file). Output is a correctly formatted FASTA file. Usage and option summary Usage: haphpipe ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Output files: ph_summary.txt ph_haplotypes.fna Input/Output Arguments: Option Description --haplotypes_fa Haplotype file created by PredictHaplo. --outdir Output directory (default: current directory). Options: Option Description --prefix Prefix to add to sequence names. --keep_gaps Do not remove gaps from alignment (default: False). Settings: Option Description --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage By default, PredictHaplo outputs their own unique version of a fasta file. It includes the frequency, some information regarding their unqiue overlapping scores, and their unique confidence scores. This file is always named PH#.best_#_#.fas , where the first number is the reconstructed haplotype number and the next numbers are the start and end of the longest haplotype reconstructed by PredictHaplo. $ cat PH01.best_1_1208.fas reconstructed_0 ;Freq:0.190638 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~n7~~~y~~~~~t~~~i~jjk~~zz ;~~~~{~~~~~N{~{~Sx~~~~~~z~K~F~~~~~~~y~~~~~~~|~~F~wx|~~{~~|~~s |]~~~~~~ ;~m~kj|{|v~{|_`~~~z~~~~~~~jy{y~~~~~a~__~~|~~~~~{wXZ~}~~~qm~xV~~~~~~~}~ ;Q~}~y||~~~}}~~~z~~~~~~{}A~}b|~~u~~|}}|~}}z~}bx~~n||~~||{~}~~d}~bz~~~} ;|~}}~~~}~~~{|}}g{~~~}~r~}}~~~~u~~{kx{~}~}~|~}~}{}~}~}||~~~~[~}~}}~~~~ ;~~}~~~U||U}~|}}~~}}~~~~}u~b|}~w~~~~~{}|wv~}Dxzp{|}~@~~P~}~}~V~~z}~|ry ;q~}|}~}~~}t~o~}~f}~~}{~~~}~{~~~~~~~}~~}~~|~~~M~~}~}x~}c~}^v~~~yzA~}~} ;y}~z}~~~~~~~~~{z~~}~~~}~{}~~~~~}~~~~~~~|~~v~~}~~|y~]|{~||~~~~~~~~||~~ ;Y||~~|Q~|~~~|~~~~~|~~~z~~z~{{{y~~~~~~~~~~w{{~wz|~Z|~z|~~}p|~~|}}~~x}} ;z}~}}|a|}}}}{}|~~}}~}}~}~{~|~}}~}{}|}|}}}~|}}}}{}}}|}}|}|}}}|}}}}~}}} ;||}}}}{}}~}~}}}}}}}}}}}~}}}}}}}}}}}}}}}}}y}~}}}}}}}}}}~|}}}}|}}}}|}}} ;}}}}}}}}|}}}}}}}}~}}}}}}|}}}}}}}}|}}}}}|}}}}|~|}}}}{}}}}}}}}}}}}}}}}} ;}}=}}}{}}}}}}}}}}}}}}}}}}}}}}}}~||}}|~}}}}}{}}}}}|}}|}}}}}}}}}}}}}|}} ;|}~}}}}|}}}}}}}}|}|~J}}}}}}~}}}}}}}}}}}}}}}}}}}}|}}`~}}}}|}}}}}}}}}}~ ;|}}}}}}}}}}}~}}}|}}}}}}}}}}|}}}}}}}}}}}t}}{}`}}}}}}|}~}~}|~}}}|k}}}}} ;|}|~}}|}}~}}~}|}}z}}}}}}}}}}}}}}~}}~}}}~~}|}}}~}}}}}}}}~}~}}||~~}~z}} ;~~}~}||~|~}|{}||~|z~~||}~|~}}|}~~}|}}~}}|}z~~~~{~}{}~y~~~~~{|}}~~|y~~ ;~|~~||~~~~~~~|n~~{~~~~~~~~~~~~~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 ;Freq:0.294104 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~z~~~~~~~~~|~y~~~~u}|~~~~~}}~~~~~~~ya~|~~}}~~~y~~~j~YXH~~s~ ;~~~~z~~|~~b|}^}xZ}}~}z~t~r~{}~}x}}yb}~~~}~}u~~}~gu|}}{~|}}~ozsw}|}}h~ ;|l}v|^][t}zz}vw}}s}}}}~v}|~|~~}}}~~}}}}}~}}}}}}zo\\}}}~}vn}iv}}}}}}}}} ;v}}~|u}}}}}}}}}|}}}}}}|}^}}[}~}r}}}{|}}|t|}}{z}}pz}}{}}}}}}}v~}y|~}}} ;}}}}~}}~}}}tz}}`}}}~}}q}}}}}~}y}}|r||}}}}~}}~}}{}}}}}}}}}}}y~}}}}t}}} ;}}}}}}{|}|}}{r}}}}tv~}}}t}m|~}h}}}}}v}}qt}|y|{|u~}}|}~_}~|~~|}~|}~}|e ;Y}~}}~}}~}v}t}}}j}}~}}}~}}~|}}}}|}}|}}}~}}}}};}}~}}x}}|}}yu}}}wy`}|~~ ;{}}x}}}}}~}}}~{v}}}}}{}~}}~}~}}|}}}}}}}}}}u}}y~~{g}L}}}}}|~}{~|}|}|}} ;l}}}}{_}}}}~z~}|}~~|~~x|~}~z~~|~}~~~}~~~}y}~~|k}}Pf}w~~~~T}}}F~~}~z}{ ;{~|}|zZ~s~|}r~}}~~|}}}}}~|}}}}n}}}~}}}}~}}}}}}}}}}}|~}}}}}}~~}}~~~~~} ;N}}}}}|~}}~}}}}{}}}~}}|~~|}|}}}~|}~}}}}}}D}~}}}}}}}}}}}}}}}}|}}z}|}}} ;}k}}}}}}}}}}}}}}}}}}}|}}}}}|}}}}}|}}}}}|}}}}|~{~}}}G}~}}}}}~}}}}}}}}} ;}}h}}~|}|}}}}}}}}}}}}}}}}}}}}}}}}{}}|}}}}|~|}}}}}}}M}}}}}}}~}}}}}}}}} ;}}~|}}}}}~~~}}}~}}|}g}}}}}}}}~|}}}}}}}}}}}}}}}}}|}~t~}|}}}}}}}||~}}}} ;|}}}}~}}}}}}~}}}gi}}~}}}}}}}}}}}}|}}~}}g}~}}v}}}}}|{}}}}}}~}}~|e}}}}} ;}}|}}~}~}~}}~}|~}|}~|||}}}}|~}}~}}}}}}}}|}}~}}~}|~}|y~}~}}}}}|}}~~}~} ;}}~}~}|~}}}~}}}}~}{}}~}}~}}}||~~}||~}x|}{~|}|~~|~}}}|{~}}~}{}}||~}}}~ ;|~}~}}}~|}}~~|,~~~~~~~~~~~~~~m~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 ;Freq:0.515259 ;Overlap quality scores (5,10):4,4 ;Confidence scores ;~~~~~~~w~~zz~~~~z~~w~|wy~|~~{|~~|~~~~~~~~}~{~hD~~~}|~|}}t~~_;~tue}}S} ;~}~~p}}l}~P}}ZlvL~z}}h~g~A~x}}}s}}{S~}~}}}}l}~|}SOq}}q}w}}~i\\pz~w~~z~ ;}7~|vzUu4|smtgm}~W}}~~}r}n`f`}{PZLSI:Vs_V_}}}}_ db}}}}}CQ}YJ}t}}}~}}} ;T}}~|}}}}}}}~}}k}}}}}}q}L}}]}}}L}}}tt|~}{q}}{M}lAIu}}}s{}}}~y~}st}|}} ;z}}}}|}}}}}{q|}Z}}}}}}P~}|}|}}E}}cLbi}vu}}|}}|}g}}}}}}|}~}~{}~}|}{}}} ;}~}|}}}{{|~}pp}~~~{|}}~}[yEx}}\\}}}{}N}uoK}}pauSy}}}v~~J}}q}}v~}c}~}\\i ;]|}}~}|}~}r}Y}}}B}}~||~}}}}{}}}|}|~|}~~~~}}~{w}{}~|R|}s|}k{~}}}ra}q}} ;o}}d}~}}}}}~}}|X~}}~}e}}}}}}}|}y|}}}}~}|~}c~~b~~nL~a}}}}}~}}m}}~{}}}} ;g}}}}uLm~l}}`~|n}}~}}|d~~y~u}|tz~~~~|}}~~t}}}tx}|Tu~v}}~}^|~~w~|~}m{} ;u}}}|w;}{}{}r}||}}z|}|~|}z}||}y}}}~}}}|}}~}}}|}y}}}}}}}~}||}}}}}}~}}| ;v{}|}}{}}}|~|}}|}}}}}}}}}}|}}}}}|}~}}}}}}p}}||}}}}}~}}}{}}}}}}}z}}}}} ;}|}}~}}}|}}}}}}}}}}}}}}}}}}}}}}|}||}}|}|}}}}|}|}}}}u}}}}}}}}}}}}}}}}} ;}}g}}}{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}}}}|}m}}}}}}}}}}}}}}}}} ;}}}}}}}}}}}}}}}}}}|}i}}}}}}}}}}|}}}}}}}}}}}}}}}}}}}H}}}}}}}}}|}{}}}}} ;|}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}|}H}}}}}}}}}}}}}}}}}}u}}}}} ;}}}}}}}}}}}}}}}}}z}}}}}}}}}}}}}}}}|}}}|}}}}}}}}}|}}}}}}}}}}}}|}}}}|}} ;}}}}}}}}}}}}||}|}}|}}}}}}|}}|}}}~}|}|}}}|}{}}}}|}}}}|{|}}}}x||}}}|{}} ;}}}}}}}~}}~}~|n}~}}}}}~}}~~|~~~y~, ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC ph_parser takes this output and creates a proper fasta file with each resontructed haplotype and a text file that has the hpalotype diversity estimate. $ cat ph_summary.txt PH_num_hap 3 PH_hap_diversity 0.611668153059 PH_seq_len 1208 $ cat ph_haplotypes.fna reconstructed_0 Freq=0.190638 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 Freq=0.294104 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 Freq=0.515259 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC hp_annotate pairwise_align Apply correct coordinate system to final sequence(s) to facilitate downstream analyses. Input is the final sequence file in FASTA format, a reference sequence in FASTA format, and a reference GFT file. Output is a JSON file to be used in extract_pairwise . Usage and option summary Usage: haphpipe pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage extract_pairwise Extract sequence regions from the pairwise alignment produced in pairwise_align . Input is the JSON file from pairwise_align . Output is either an unaligned nucleotide FASTA file, an aligned nucleotide FASTA file, an amino acid FASTA file, an amplicon GTF file, or a tab-separated values (TSV) file (default: nucleotide FASTA with regions of interest from GTF file used in pairwise_align ). Usage and option summary Usage: haphpipe extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] (or): hp_extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False). Example usage * annotate_ from_ref* Annotate consensus sequence from reference annotation. Input is JSON file from pairwise_align and reference GTF file. Usage and option summary Usage: haphpipe annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Example usage --- Example usage hp_assemble_01 hp_assemble_02 HIV Data from NCBI bioproject: PRJNA486832 with associated article . Brief description of the paper and data: insert from students Quick start Miniconda and Bioconda Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge Downloading data This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the first 20 accessions from the SRA list, and only pulls 20,000 reads from SRA data. We pulled the first 20 in order, because thier paper says that between 22-24 samples were put on a single MiSeq run. This code says for each accession in the accession list, sort them in order, and then take the first 20 accession numbers. For each of these 20 accession numbers, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt | sort | head -n 20); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate Installing HAPHPIPE insert from students Activating HAPHPIPE insert from students HAPHPIPE suite insert from students hp_reads sample_reads trim_reads join_reads ec_reads hp_assemble assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly hp_haplotype predict_haplo ph_parser hp_annotate pairwise_align extract_pairwise annotate_from_ref Example usage Your virus with both pipelines. Document all code and explanation. Starting directory structure insert from students Ending directory structure insert from students Helpful sources bash scripting conda FAQ HCV Data from NCBI bioproject: PRJNA237978 with associated article . Brief description of the paper and data: insert from students Quick start Miniconda and Bioconda Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge Downloading data This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the all the accessions (23) from the SRA list, and only pulls 20,000 reads from SRA data. This code says for each accession in the accession list, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate Installing HAPHPIPE insert from students Activating HAPHPIPE insert from students HAPHPIPE suite insert from students hp_reads sample_reads trim_reads join_reads ec_reads hp_assemble assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly hp_haplotype predict_haplo ph_parser hp_annotate pairwise_align extract_pairwise annotate_from_ref Example usage Your virus with both pipelines. Document all code and explanation. Starting directory structure insert from students Ending directory structure insert from students Helpful sources bash scripting conda **insert from students** FAQ insert from students Influenza Data from NCBI bioproject: PRJNA506454 with associated article . Brief description of the paper and data: insert from students Quick start Miniconda and Bioconda Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge Downloading data This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the 20 random accessions from the SRA list, and only pulls 20,000 reads from SRA data. We pulled randomly, because the study had two sets of influenza types sequenced, and we wanted to pull from both, but randomly This code says for each accession in the accession list, sort them randomly (the -R option applied in sort , and then take the first 20 accession numbers from that randomly sorted list. For each of these 20 accession numbers, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt | sort -R | head -n 20); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate Installing HAPHPIPE insert from students Activating HAPHPIPE insert from students HAPHPIPE suite insert from students hp_reads sample_reads trim_reads join_reads ec_reads hp_assemble assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly hp_haplotype predict_haplo ph_parser hp_annotate pairwise_align extract_pairwise annotate_from_ref Example usage Your virus with both pipelines. Document all code and explanation. Starting directory structure insert from students Ending directory structure insert from students Helpful sources bash scripting conda **insert from students** FAQ insert from students --- Advanced Usage individual modules + making your own pipelines w/ bash in advanced usage --- File extension table Module Input Input Format Output Output File Names sample_reads FASTQ file(s) .fastq.gz or .fastq or .fq Subampled FASTQ file(s) sample_1.fastq sample_2.fastq trim_reads FASTQ file(s) .fastq.gz or .fastq or .fq Trimmed FASTQ file(s) and summary from Trimmomatic text file trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out join_reads FASTQ file(s) .fastq.gz or .fastq or .fq FASTQ files for joined reads and unjoined reads joined.fastq notjoined_1.fastq notjoined_2.fastq ec_reads FASTQ file(s) .fastq.gz or .fastq or .fq Error corrected FASTQ file(s) corrected_1.fastq corrected_2.fastq corrected_U.fastq assemble_denovo FASTQ file(s) .fastq.gz or .fastq or .fq De novo assembled contigs FASTA file and de novo summary text file denovo_contigs.fna denovo_summary.txt assemble_amplicons FASTA files and GTF file .fna or .fasta or .fa and .gtf FASTA file with assembled amplicons amplicon_assembly.fna assemble_scaffold FASTA files .fna or .fasta or .fa FASTA files with scaffolded and aligned sequences and FASTA file with assembled amplicons scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out align_reads FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa Aligned BAM file and Bowtie2 alignment output summary text file aligned.bam aligned.bt2.out call_variants BAM and FASTA file .bam and .fna or .fasta or .fa VCF file with variants variants.vcf.gz vcf_to_consensus VCF file .vcf FASTA file with consensus sequence consensus.fna refine_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with refined consensus sequence refined.fna finalize_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with final refined consensus sequence and final BAM file with reads aligned to final FASTA file and VCF file with variants relative to final.fna final.fna and final.bam and final.vcf.gz predict_haplo FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa PredictHaplo's fasta-like output file best.fa ph_parser PredictHaplo's FAS output file .fas Summary text file with haplotype diversity statistics and FASTA file with haplotype sequences ph_summary.txt and ph_haplotypes.fna pairwise_align FASTA files and GTF file .fna or .fasta or .fa and .gtf JSON file pairwise_aligned.json extract_pairwise JSON file from pairwise_align output .json FASTA output with region extracted to standard out stdout.fasta annotate_from_ref JSON file from pairwise_align output and GTF file .json and .gtf --- Helpful resources Conda Bioconda Bioconda channels Bash Command line tutorial List of bash commands Bash scripting tutorial Additional scripting help: linuxconfig.org flaviocopesc.com ryanstutorials.net NGS overview: NYU resource Accessing on a PC using a virtual machine Guide to options VirtualBox --- FAQ what is directory structure? --- Related software","title":"Haphpipe User Guide"},{"location":"haphpipe_userguide/#haphpipe-user-guide","text":"HA plotype and PH ylodynamics pipeline for viral assembly, population genetics, and phylodynamics. We assume basic familiarity with conda environments, basic bash knowledge and knowledge of general next-generation sequencing (NGS) concepts. For more information regarding all of these, see helpful links and FAQ. (insert links to markdown pages once these are split up) Remember that a directory is a simply a folder nesting system, similar to what you see on your computer. Where you see \"folder\" below you can also say \"directory.\" HAPHPIPE is intended only for Linux and Mac OS X platforms. This User Guide was developed by undergrads and graduate students to be accessible for users at all stages. Maggie Steiner, Keylie M Gibson, Matthew L Bendall, .... all contributed to developing this User Guide and testing HAPHPIPE. See paper for more information and paper for validation study. Citing HAPHPIPE: insert eventually I want each of these a separate document, for now I'll just make a giant one.","title":"Haphpipe User Guide"},{"location":"haphpipe_userguide/#installation","text":"For now, the installation goes like this. We are hoping to make it into a stand alone bioconda recipe soon. HAPHIPE depends on more than a dozen different programs, each of which may itself depend on other programs and libraries. Installing everything separately would be a nightmare, so you should use the package manager \"Bioconda\" to install everything. Bioconda is a popular package manager in the bioinformatics world. See helpful links for more information and resources for Bioconda. This User Guide describes where to get Bioconda and how to install it, then how to use Bioconda to install the necessary programs for HAPHPIPE. This User Guide details the acquisition and installation of one program, GTAK, that is not handled by Bioconda, and finally the acquisition and installation of HAPHPIPE itself. Here, we describe the procedure for installing HAPHPIPE using the package manager Bioconda (Gr\u00fcning et al. 2018) on the command line. If you are unfamiliar with Bioconda, please see https://bioconda.github.io for installation and channel setup. HAPHPIPE is available at https://github.com/gwcbi/haphpipe and is written in Python 3.7.2 coding language. An online documentation is available at https://github.com/gwcbi/haphpipe/wiki. The installation process begins with the creation of a conda environment that installs the necessary dependencies required by HAPHPIPE. Once the conda environment has been created, it can be activated for use with the command conda activate haphpipe. Due to license restrictions, Bioconda cannot distribute and install GATK (McKenna et al. 2010; Van der Auwera et al. 2013; Poplin et al. 2018) directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute (https://software.broadinstitute.org/gatk/download/archive). You can then install HAPHPIPE using the single command pip install git+git://github.com/gwcbi/haphpipe.git, which pulls the repository from Github. 1. Install conda Download the conda package: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh 2. Set up conda channels These need to be put in as a command in the order they come, as this sets the priority for where packages are pulled from. Therefore, in this order, conda-forge is top priority and explored first when downloading a program. conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge 3. Create a conda environment with the following dependencies conda create -n haphpipe \\ python \\ future \\ pyyaml \\ biopython \\ seqtk \\ bowtie2 \\ bwa \\ flash \\ freebayes \\ mummer \\ picard \\ trimmomatic \\ samtools=1.9 \\ gatk=3.8 \\ spades \\ blast \\ sierrapy 4. Activate the environment conda activate haphpipe 5. Install GATK GATK can be dowloaded before or after creating the haphpipe conda environment, but it must be registered after creating the conda environment. Due to license restrictions, bioconda cannot distribute and install GATK directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute: https://software.broadinstitute.org/gatk/download/archive . Once you download a copy, register the package using gatk3-register : gatk3-register /path/to/GenomeAnalysisTK-3.8-0-ge9d806836.tar.bz2 This will copy GATK into your conda environment. NOTE: HAPHPIPE was developed and tested using GATK 3.8. 6. Install HAPHPIPE pip install git+git://github.com/gwcbi/haphpipe.git Upon completion of the installation, you can test it to ensure the repository has been installed completely and correctly by running haphpipe -h (in quick start). Once HAPHPIPE is installed and performing correctly, there is no need to install it again; simply activate the conda environment when needed by executing conda activate haphpipe . If a new version is released in the future, HAPHPIPE can be updated by running the command line pip install --upgrade git+git://github.com/gwcbi/haphpipe.git . At any point, the -h option that follows any HAPHPIPE stage will output a help message that provides a description of the stage and the desired input(s) and output(s). 7. Installing PredictHaplo The user is required to install PredictHaplo on their own, as there are system-dependent variables within the installation process. We were unable to successfully incorporate PredictHaplo into HAPHPIPE so this step was unnecessary for you to install. Users are required to download PredictHaplo on their own computing system prior to running any of the haplotype stages ( hp_predict_haplo and hp_ph_parser ). Here is how the GW CBI team installed PredictHaplo onto our HPC, which has a slurm scheduling system and uses Lua module files. We cannot help with the installation of this software, but have provided the code that we used here to install PredictHaplo onto our system. Please see their website for contact information if you need help installing their program. You can download the new version for paired-end reads of the PredictHaplo program from their website . The instructions are in the README in the folder downloaded. We have also provided them here for your access. provide the readme file for them This module loads predicthaplo onto GWU's HPC - Colonial One. See https://bmda.dmi.unibas.ch/software.html cd /path/to/modules/predicthaplo # use gcc 4.9.4, add blas and lapack to library path module load gcc/4.9.4 module load blas/gcc/64 module load lapack/gcc/64 # download source cd archive wget https://bmda.dmi.unibas.ch/software/PredictHaplo-Paired-0.4.tgz cd .. # unzip source and change directory name tar xfvz archive/PredictHaplo-Paired-0.4.tgz mv PredictHaplo-Paired-0.4 0.4 cd 0.4 # install scythestat tar xfvz scythestat-1.0.3.tar.gz cd scythestat-1.0.3 ./configure --prefix=/path/to/modules/predicthaplo/0.4/NEWSCYTHE make install cd .. # compile predicthaplo make If a segfault error occurs during the hp_predict_haplo stage, this is not a characteristic of HAPHPIPE but rather that of PredictHaplo. Sometimes, we have luck if we just rerun the code again or move to an interactive CPU node. We are unsure what causes this error, and we only see it between the local and global reconstruction phases in PredictHaplo.","title":"Installation"},{"location":"haphpipe_userguide/#-","text":"","title":"---"},{"location":"haphpipe_userguide/#quick-start","text":"","title":"Quick start"},{"location":"haphpipe_userguide/#activate-haphpipe","text":"1. Activate haphpipe Make sure you have conda running. For students at GW using Colonial One, you need to load the miniconda3 module like such prior to activating the haphpipe conda environemnt: module load miniconda3 . conda activate haphpipe 2. Test that it is loaded correctly haphpipe -h should produce: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data","title":"Activate HAPHPIPE"},{"location":"haphpipe_userguide/#demo","text":"Demo1, de novo assembly, tell them exactly what fastq read files they need to download, exactly where to find those files, and exactly where to download them. Provide URLs and what to expect to see in the SRL archives. These are beginners, they don't know how to find anything. Then tell them that Demo2 you will lead them through a reference guided assembly and that they will need to download the following finished genomes sequences and exactly where to get them We will now go over two ways to complete these demos: (i) automatically, which is to ultimately test if HAPHPIPE has been installed correctly and (ii) interactively, to get a feel and experience running HAPHPIPE yourself. Data for both demos is included in the repository. Both samples should run quickly (less than five minutes using eight CPUs). Note: ensure PredictHaplo is installed prior to running the demos. Automatically to test the installation of HAPHPIPE insert the code to run the demo data Interactively to familiarize yourself with running HAPHPIPE","title":"Demo"},{"location":"haphpipe_userguide/#example-pipelines","text":"The example pipelines are written in bash scripting language. The reference files used in both examples are included in the demo data. To run in haphpipe, execute one of the following lines: Pipeline 1 implements amplicon assembly using a de novo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Pipeline 2 implements amplicon assembly using a reference-based mapping approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps.","title":"Example pipelines"},{"location":"haphpipe_userguide/#pipeline-1-haphpipe_assemble_01","text":"This pipeline implements de novo assembly. Reads are first trimmed ( trim_reads ) and used as input for denovo assembly ( assemble_denovo ). The de novo assembly stage automatically performs error correction on the trimmed reads. The assembled contigs are used as input for amplicon assembly ( assemble_amplicons ) along with reference FASTA and GTF files. The assembly is then iteratively refined up to five times ( refine_assembly ) by mapping corrected reads to the assembled FASTA file and lastly finalized ( finalize_assembly ), resulting in a FASTA file with final consensus sequences, final VCF, and aligned BAM file. To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_01 -h , and it will show the output: USAGE: haphpipe_assemble_01 [read1] [read2] [reference_fasta] [reference_gtf] [samp_id] outdir ----- HAPHPIPE assembly pipeline 01 ----- This pipeline implements amplicon assembly using a denovo approach. Reads are error-corrected and used to refine the initial assembly, with up to 5 refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) reference_fasta: Reference sequence (fasta) reference_gtf: Amplicon regions (GTF) samp_id: Sample ID outdir: Output directory (default is [sample_dir]/haphpipe_assemble_01) General command to execute pipeline 1: haphpipe_assemble_01 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta refs/ref.gtf samp Example command to run with demo01: insert","title":"Pipeline 1: haphpipe_assemble_01"},{"location":"haphpipe_userguide/#pipeline-2-haphpipe_assemble_02","text":"This pipeline implements reference-based mapping assembly. Reads are first trimmed ( trim_reads ) and error-corrected ( ec_reads ). The corrected reads are used as input for reference-based mapping assembly ( refine_assembly ) for up to five iterations. Lastly, the assembly is finalized ( finalize_assembly ) by mapping reads onto the refined reference sequence. The final output is a FASTA file with final consensus sequences, final VCF, and aligned BAM file. (insert Figure 2 here) To see the input information for Pipeline 1, use the -h option again like so: haphpipe_assemble_02 -h , and it will show the output: USAGE: haphpipe_assemble_02 [read1] [read2] [amplicons_fasta] [samp_id] outdir ----- HAPHPIPE assembly pipeline 02 ----- This pipeline implements amplicon assembly using a reference-based approach. Reads are error-corrected and aligned to provided amplicon reference with up to five refinement steps. Input: read1: Fastq file for read 1. May be compressed (.gz) read2: Fastq file for read 2. May be compressed (.gz) amplicons_fasta: Amplicon reference sequence (fasta) samp_id: Sample ID outdir: Output directory (default is sample_dir/haphpipe_assemble_02) General command to execute pipeline 1: haphpipe_assemble_02 samp/read1.fq.gz samp/read2.fq.gz refs/ref.fasta samp Example command to run with demo01: insert","title":"Pipeline 2: haphpipe_assemble_02"},{"location":"haphpipe_userguide/#-_1","text":"","title":"---"},{"location":"haphpipe_userguide/#haphpipe-suite","text":"Each stage can be run on its own. Stages are grouped into 4 categories: hp_reads , hp_assemble , hp_haplotype , and hp_annotate . More detailed description of command line options for each stage are available in the wiki . To view all available stages in HAPHPIPE, run: haphpipe -h Output will look like: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data HAPHPIPE consists of a suite of sub-commands under each stage that are invoked as follows: haphpipe [stage] [sub-command] [options] For example, to join paired end reads, one would invoke the following: haphpipe join_reads --fq1 trimmed_1.fastq --fq2 trimmed_2.fastq I want all stages to have a table like this detailing the options like this.","title":"HAPHPIPE suite"},{"location":"haphpipe_userguide/#hp_reads","text":"hp_reads involves cleaning up the raw read sequences, as well as other processing steps. Modules to manipulate reads.","title":"hp_reads"},{"location":"haphpipe_userguide/#sample_reads","text":"Subsample reads using seqtk ( documentation ). Input is reads in FASTQ format. Output is sampled reads in FASTQ format. You do not have to have all read options (i.e., read1, read2 AND unpaired reads). You can have a combination of any of those.","title":"sample_reads"},{"location":"haphpipe_userguide/#usage-and-option-summary","text":"Usage: haphpipe sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False.","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage","text":"This pulls 1000 reads from these paired end files with a starting seed of 1234. haphpipe sample_reads --fq1 read_1.fastq --fq2 read_2.fastq --nreads 1000 --seed 1234 --","title":"Example usage"},{"location":"haphpipe_userguide/#trim_reads","text":"Trim reads using Trimmomatic ( documentation ). Input is reads in FASTQ format. Output is trimmed reads in FASTQ format.","title":"trim_reads"},{"location":"haphpipe_userguide/#usage-and-option-summary_1","text":"Usage: haphpipe trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_1","text":"This trims paired end read files 1 and 2. haphpipe trim_reads --fq1 read_1.fastq --fq2 read_2.fastq --","title":"Example usage"},{"location":"haphpipe_userguide/#join_reads","text":"Join reads using FLASH ( paper ). Input is reads in FASTQ format. Output is joined reads in FASTQ format.","title":"join_reads"},{"location":"haphpipe_userguide/#usage-and-option-summary_2","text":"Usage: haphpipe join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] (or): hp_join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_2","text":"--","title":"Example usage"},{"location":"haphpipe_userguide/#ec_reads","text":"Error correction using SPAdes ( documentation ). Input is reads in FASTQ format. Output is error-corrected reads in FASTQ format. Remember that HAPHPIPE is intended for Illumina reads, therefore the error correction is based on Illumina sequencing errors.","title":"ec_reads"},{"location":"haphpipe_userguide/#usage-and-option-summary_3","text":"Usage: haphpipe ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False.","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_3","text":"--","title":"Example usage"},{"location":"haphpipe_userguide/#hp_assemble","text":"Assemble consensus sequence(s). Input reads (in FASTQ format) are assembled using either denovo assembly or reference-based alignment. Resulting consensus can be further refined.","title":"hp_assemble"},{"location":"haphpipe_userguide/#assemble_denovo","text":"Assemble reads via de novo assembly using SPAdes ( documentation ). Input is reads in FASTQ format. Output is contigs in FNA format.","title":"assemble_denovo"},{"location":"haphpipe_userguide/#usage-and-option-summary_4","text":"Usage: haphpipe assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_4","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#assemble_amplicons","text":"Assemble contigs from de novo assembly using both a reference sequence and amplicon regions with MUMMER 3+ ( documentation ). Input is contigs and reference sequence in FASTA format and amplicon regions in GTF format.","title":"assemble_amplicons"},{"location":"haphpipe_userguide/#usage-and-option-summary_5","text":"Usage: haphpipe assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_5","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#assemble_scaffold","text":"Scaffold contigs against a reference sequence with MUMMER 3+ ( documentation ). Input is contigs in FASTA format and reference sequence in FASTA format. Output is scaffold assembly, alligned scaffold, imputed scaffold, and padded scaffold in FASTA format.","title":"assemble_scaffold"},{"location":"haphpipe_userguide/#usage-and-option-summary_6","text":"Usage: haphpipe assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] (or): hp_assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_6","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#align_reads","text":"Map reads to reference sequence (instead of running de novo assembly) using Bowtie2 ( documentation ) and Picard ( documentation ). Input is reads in FASTQ format and reference sequence in FASTA format.","title":"align_reads"},{"location":"haphpipe_userguide/#usage-and-option-summary_7","text":"Usage: haphpipe align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_7","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#call_variants","text":"Variant calling from alignment using GATK ( documentation ). Input is alignment file in BAM format and reference sequence in FASTA format (either reference from reference-based assembly or consensus final sequence from de novo assembly). Output is a Variant Call File (VCF) format file.","title":"call_variants"},{"location":"haphpipe_userguide/#usage-and-option-summary_8","text":"Usage: haphpipe call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] (or): hp_call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_8","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#vcf_to_consensus","text":"Generate a consensus sequence from a VCF file. Input is a VCF file. Output is the consensus sequence in FASTA format.","title":"vcf_to_consensus"},{"location":"haphpipe_userguide/#usage-and-option-summary_9","text":"Usage: haphpipe vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] (or): hp_vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file.","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_9","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#refine_assembly","text":"Map reads to a denovo assembly or reference alignment. Assembly or alignment is iteratively updated. Input is reads in FASTQ format and reference sequence (assembly or reference alignment) in FASTA format. Output is refined assembly in FASTA format.","title":"refine_assembly"},{"location":"haphpipe_userguide/#usage-and-option-summary_10","text":"Usage: haphpipe refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_10","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#finalize_assembly","text":"Finalize consensus, map reads to consensus, and call variants. Input is reads in FASTQ format and reference sequence in FASTA format. Output is finalized reference sequence, alignment, and variants (in FASTA, BAM, and VCF formats, respectively).","title":"finalize_assembly"},{"location":"haphpipe_userguide/#usage-and-option-summary_11","text":"Usage: haphpipe finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_11","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#hp_haplotype","text":"Haplotype assembly stages. HAPHPIPE implements PredictHaplo ( paper ), although other haplotype reconstruction programs can be utilized outside of HAPHPIPE using the final output of HAPHPIPE, typically with the final consensus sequence (FASTA) file, reads (raw, trimmed, and/or corrected), and/or final alignment (BAM) file as input.","title":"hp_haplotype"},{"location":"haphpipe_userguide/#predict_haplo","text":"Haplotype identification with PredictHaplo. Input is reads in FASTQ format and and reference sequence in FASTA format. Output is the longest global haplotype file and corresponding HTML file. Note: PredictHaplo must be installed separately before running this stage.","title":"predict_haplo"},{"location":"haphpipe_userguide/#usage-and-option-summary_12","text":"Usage: haphpipe predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] (or): hp_ predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] Output files: best.fa Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --ref_fa Reference sequence used to align reads (Fasta). --interval_txt File with intervals to perform haplotype reconstruction. --outdir Output directory (default: current directory). Options: Option Description --min_readlength Minimum read length passed to PredictHaplo (default: 36). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_12","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#ph_parser","text":"Returns PredictHaplo output as a correctly formatted FASTA file. Input is the output file from predict_haplo (longest global .fas file). Output is a correctly formatted FASTA file.","title":"ph_parser"},{"location":"haphpipe_userguide/#usage-and-option-summary_13","text":"Usage: haphpipe ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Output files: ph_summary.txt ph_haplotypes.fna Input/Output Arguments: Option Description --haplotypes_fa Haplotype file created by PredictHaplo. --outdir Output directory (default: current directory). Options: Option Description --prefix Prefix to add to sequence names. --keep_gaps Do not remove gaps from alignment (default: False). Settings: Option Description --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file.","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_13","text":"By default, PredictHaplo outputs their own unique version of a fasta file. It includes the frequency, some information regarding their unqiue overlapping scores, and their unique confidence scores. This file is always named PH#.best_#_#.fas , where the first number is the reconstructed haplotype number and the next numbers are the start and end of the longest haplotype reconstructed by PredictHaplo. $ cat PH01.best_1_1208.fas reconstructed_0 ;Freq:0.190638 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~n7~~~y~~~~~t~~~i~jjk~~zz ;~~~~{~~~~~N{~{~Sx~~~~~~z~K~F~~~~~~~y~~~~~~~|~~F~wx|~~{~~|~~s |]~~~~~~ ;~m~kj|{|v~{|_`~~~z~~~~~~~jy{y~~~~~a~__~~|~~~~~{wXZ~}~~~qm~xV~~~~~~~}~ ;Q~}~y||~~~}}~~~z~~~~~~{}A~}b|~~u~~|}}|~}}z~}bx~~n||~~||{~}~~d}~bz~~~} ;|~}}~~~}~~~{|}}g{~~~}~r~}}~~~~u~~{kx{~}~}~|~}~}{}~}~}||~~~~[~}~}}~~~~ ;~~}~~~U||U}~|}}~~}}~~~~}u~b|}~w~~~~~{}|wv~}Dxzp{|}~@~~P~}~}~V~~z}~|ry ;q~}|}~}~~}t~o~}~f}~~}{~~~}~{~~~~~~~}~~}~~|~~~M~~}~}x~}c~}^v~~~yzA~}~} ;y}~z}~~~~~~~~~{z~~}~~~}~{}~~~~~}~~~~~~~|~~v~~}~~|y~]|{~||~~~~~~~~||~~ ;Y||~~|Q~|~~~|~~~~~|~~~z~~z~{{{y~~~~~~~~~~w{{~wz|~Z|~z|~~}p|~~|}}~~x}} ;z}~}}|a|}}}}{}|~~}}~}}~}~{~|~}}~}{}|}|}}}~|}}}}{}}}|}}|}|}}}|}}}}~}}} ;||}}}}{}}~}~}}}}}}}}}}}~}}}}}}}}}}}}}}}}}y}~}}}}}}}}}}~|}}}}|}}}}|}}} ;}}}}}}}}|}}}}}}}}~}}}}}}|}}}}}}}}|}}}}}|}}}}|~|}}}}{}}}}}}}}}}}}}}}}} ;}}=}}}{}}}}}}}}}}}}}}}}}}}}}}}}~||}}|~}}}}}{}}}}}|}}|}}}}}}}}}}}}}|}} ;|}~}}}}|}}}}}}}}|}|~J}}}}}}~}}}}}}}}}}}}}}}}}}}}|}}`~}}}}|}}}}}}}}}}~ ;|}}}}}}}}}}}~}}}|}}}}}}}}}}|}}}}}}}}}}}t}}{}`}}}}}}|}~}~}|~}}}|k}}}}} ;|}|~}}|}}~}}~}|}}z}}}}}}}}}}}}}}~}}~}}}~~}|}}}~}}}}}}}}~}~}}||~~}~z}} ;~~}~}||~|~}|{}||~|z~~||}~|~}}|}~~}|}}~}}|}z~~~~{~}{}~y~~~~~{|}}~~|y~~ ;~|~~||~~~~~~~|n~~{~~~~~~~~~~~~~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 ;Freq:0.294104 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~z~~~~~~~~~|~y~~~~u}|~~~~~}}~~~~~~~ya~|~~}}~~~y~~~j~YXH~~s~ ;~~~~z~~|~~b|}^}xZ}}~}z~t~r~{}~}x}}yb}~~~}~}u~~}~gu|}}{~|}}~ozsw}|}}h~ ;|l}v|^][t}zz}vw}}s}}}}~v}|~|~~}}}~~}}}}}~}}}}}}zo\\}}}~}vn}iv}}}}}}}}} ;v}}~|u}}}}}}}}}|}}}}}}|}^}}[}~}r}}}{|}}|t|}}{z}}pz}}{}}}}}}}v~}y|~}}} ;}}}}~}}~}}}tz}}`}}}~}}q}}}}}~}y}}|r||}}}}~}}~}}{}}}}}}}}}}}y~}}}}t}}} ;}}}}}}{|}|}}{r}}}}tv~}}}t}m|~}h}}}}}v}}qt}|y|{|u~}}|}~_}~|~~|}~|}~}|e ;Y}~}}~}}~}v}t}}}j}}~}}}~}}~|}}}}|}}|}}}~}}}}};}}~}}x}}|}}yu}}}wy`}|~~ ;{}}x}}}}}~}}}~{v}}}}}{}~}}~}~}}|}}}}}}}}}}u}}y~~{g}L}}}}}|~}{~|}|}|}} ;l}}}}{_}}}}~z~}|}~~|~~x|~}~z~~|~}~~~}~~~}y}~~|k}}Pf}w~~~~T}}}F~~}~z}{ ;{~|}|zZ~s~|}r~}}~~|}}}}}~|}}}}n}}}~}}}}~}}}}}}}}}}}|~}}}}}}~~}}~~~~~} ;N}}}}}|~}}~}}}}{}}}~}}|~~|}|}}}~|}~}}}}}}D}~}}}}}}}}}}}}}}}}|}}z}|}}} ;}k}}}}}}}}}}}}}}}}}}}|}}}}}|}}}}}|}}}}}|}}}}|~{~}}}G}~}}}}}~}}}}}}}}} ;}}h}}~|}|}}}}}}}}}}}}}}}}}}}}}}}}{}}|}}}}|~|}}}}}}}M}}}}}}}~}}}}}}}}} ;}}~|}}}}}~~~}}}~}}|}g}}}}}}}}~|}}}}}}}}}}}}}}}}}|}~t~}|}}}}}}}||~}}}} ;|}}}}~}}}}}}~}}}gi}}~}}}}}}}}}}}}|}}~}}g}~}}v}}}}}|{}}}}}}~}}~|e}}}}} ;}}|}}~}~}~}}~}|~}|}~|||}}}}|~}}~}}}}}}}}|}}~}}~}|~}|y~}~}}}}}|}}~~}~} ;}}~}~}|~}}}~}}}}~}{}}~}}~}}}||~~}||~}x|}{~|}|~~|~}}}|{~}}~}{}}||~}}}~ ;|~}~}}}~|}}~~|,~~~~~~~~~~~~~~m~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 ;Freq:0.515259 ;Overlap quality scores (5,10):4,4 ;Confidence scores ;~~~~~~~w~~zz~~~~z~~w~|wy~|~~{|~~|~~~~~~~~}~{~hD~~~}|~|}}t~~_;~tue}}S} ;~}~~p}}l}~P}}ZlvL~z}}h~g~A~x}}}s}}{S~}~}}}}l}~|}SOq}}q}w}}~i\\pz~w~~z~ ;}7~|vzUu4|smtgm}~W}}~~}r}n`f`}{PZLSI:Vs_V_}}}}_ db}}}}}CQ}YJ}t}}}~}}} ;T}}~|}}}}}}}~}}k}}}}}}q}L}}]}}}L}}}tt|~}{q}}{M}lAIu}}}s{}}}~y~}st}|}} ;z}}}}|}}}}}{q|}Z}}}}}}P~}|}|}}E}}cLbi}vu}}|}}|}g}}}}}}|}~}~{}~}|}{}}} ;}~}|}}}{{|~}pp}~~~{|}}~}[yEx}}\\}}}{}N}uoK}}pauSy}}}v~~J}}q}}v~}c}~}\\i ;]|}}~}|}~}r}Y}}}B}}~||~}}}}{}}}|}|~|}~~~~}}~{w}{}~|R|}s|}k{~}}}ra}q}} ;o}}d}~}}}}}~}}|X~}}~}e}}}}}}}|}y|}}}}~}|~}c~~b~~nL~a}}}}}~}}m}}~{}}}} ;g}}}}uLm~l}}`~|n}}~}}|d~~y~u}|tz~~~~|}}~~t}}}tx}|Tu~v}}~}^|~~w~|~}m{} ;u}}}|w;}{}{}r}||}}z|}|~|}z}||}y}}}~}}}|}}~}}}|}y}}}}}}}~}||}}}}}}~}}| ;v{}|}}{}}}|~|}}|}}}}}}}}}}|}}}}}|}~}}}}}}p}}||}}}}}~}}}{}}}}}}}z}}}}} ;}|}}~}}}|}}}}}}}}}}}}}}}}}}}}}}|}||}}|}|}}}}|}|}}}}u}}}}}}}}}}}}}}}}} ;}}g}}}{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}}}}|}m}}}}}}}}}}}}}}}}} ;}}}}}}}}}}}}}}}}}}|}i}}}}}}}}}}|}}}}}}}}}}}}}}}}}}}H}}}}}}}}}|}{}}}}} ;|}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}|}H}}}}}}}}}}}}}}}}}}u}}}}} ;}}}}}}}}}}}}}}}}}z}}}}}}}}}}}}}}}}|}}}|}}}}}}}}}|}}}}}}}}}}}}|}}}}|}} ;}}}}}}}}}}}}||}|}}|}}}}}}|}}|}}}~}|}|}}}|}{}}}}|}}}}|{|}}}}x||}}}|{}} ;}}}}}}}~}}~}~|n}~}}}}}~}}~~|~~~y~, ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC ph_parser takes this output and creates a proper fasta file with each resontructed haplotype and a text file that has the hpalotype diversity estimate. $ cat ph_summary.txt PH_num_hap 3 PH_hap_diversity 0.611668153059 PH_seq_len 1208 $ cat ph_haplotypes.fna reconstructed_0 Freq=0.190638 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 Freq=0.294104 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 Freq=0.515259 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC","title":"Example usage"},{"location":"haphpipe_userguide/#hp_annotate","text":"","title":"hp_annotate"},{"location":"haphpipe_userguide/#pairwise_align","text":"Apply correct coordinate system to final sequence(s) to facilitate downstream analyses. Input is the final sequence file in FASTA format, a reference sequence in FASTA format, and a reference GFT file. Output is a JSON file to be used in extract_pairwise .","title":"pairwise_align"},{"location":"haphpipe_userguide/#usage-and-option-summary_14","text":"Usage: haphpipe pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_14","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#extract_pairwise","text":"Extract sequence regions from the pairwise alignment produced in pairwise_align . Input is the JSON file from pairwise_align . Output is either an unaligned nucleotide FASTA file, an aligned nucleotide FASTA file, an amino acid FASTA file, an amplicon GTF file, or a tab-separated values (TSV) file (default: nucleotide FASTA with regions of interest from GTF file used in pairwise_align ).","title":"extract_pairwise"},{"location":"haphpipe_userguide/#usage-and-option-summary_15","text":"Usage: haphpipe extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] (or): hp_extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False).","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_15","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#annotate_-from_ref","text":"Annotate consensus sequence from reference annotation. Input is JSON file from pairwise_align and reference GTF file.","title":"* annotate_ from_ref*"},{"location":"haphpipe_userguide/#usage-and-option-summary_16","text":"Usage: haphpipe annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir]","title":"Usage and option summary"},{"location":"haphpipe_userguide/#example-usage_16","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#-_2","text":"","title":"---"},{"location":"haphpipe_userguide/#example-usage_17","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#hp_assemble_01","text":"","title":"hp_assemble_01"},{"location":"haphpipe_userguide/#hp_assemble_02","text":"","title":"hp_assemble_02"},{"location":"haphpipe_userguide/#hiv","text":"Data from NCBI bioproject: PRJNA486832 with associated article . Brief description of the paper and data: insert from students","title":"HIV"},{"location":"haphpipe_userguide/#quick-start_1","text":"","title":"Quick start"},{"location":"haphpipe_userguide/#miniconda-and-bioconda","text":"Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge","title":"Miniconda and Bioconda"},{"location":"haphpipe_userguide/#downloading-data","text":"This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the first 20 accessions from the SRA list, and only pulls 20,000 reads from SRA data. We pulled the first 20 in order, because thier paper says that between 22-24 samples were put on a single MiSeq run. This code says for each accession in the accession list, sort them in order, and then take the first 20 accession numbers. For each of these 20 accession numbers, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt | sort | head -n 20); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate","title":"Downloading data"},{"location":"haphpipe_userguide/#installing-haphpipe","text":"insert from students","title":"Installing HAPHPIPE"},{"location":"haphpipe_userguide/#activating-haphpipe","text":"insert from students","title":"Activating HAPHPIPE"},{"location":"haphpipe_userguide/#haphpipe-suite_1","text":"insert from students","title":"HAPHPIPE suite"},{"location":"haphpipe_userguide/#hp_reads_1","text":"sample_reads trim_reads join_reads ec_reads","title":"hp_reads"},{"location":"haphpipe_userguide/#hp_assemble_1","text":"assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly","title":"hp_assemble"},{"location":"haphpipe_userguide/#hp_haplotype_1","text":"predict_haplo ph_parser","title":"hp_haplotype"},{"location":"haphpipe_userguide/#hp_annotate_1","text":"pairwise_align extract_pairwise annotate_from_ref","title":"hp_annotate"},{"location":"haphpipe_userguide/#example-usage_18","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#your-virus-with-both-pipelines-document-all-code-and-explanation","text":"","title":"Your virus with both pipelines. Document all code and explanation."},{"location":"haphpipe_userguide/#starting-directory-structure","text":"insert from students","title":"Starting directory structure"},{"location":"haphpipe_userguide/#ending-directory-structure","text":"insert from students","title":"Ending directory structure"},{"location":"haphpipe_userguide/#helpful-sources","text":"bash scripting conda","title":"Helpful sources"},{"location":"haphpipe_userguide/#faq","text":"","title":"FAQ"},{"location":"haphpipe_userguide/#hcv","text":"Data from NCBI bioproject: PRJNA237978 with associated article . Brief description of the paper and data: insert from students","title":"HCV"},{"location":"haphpipe_userguide/#quick-start_2","text":"","title":"Quick start"},{"location":"haphpipe_userguide/#miniconda-and-bioconda_1","text":"Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge","title":"Miniconda and Bioconda"},{"location":"haphpipe_userguide/#downloading-data_1","text":"This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the all the accessions (23) from the SRA list, and only pulls 20,000 reads from SRA data. This code says for each accession in the accession list, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate","title":"Downloading data"},{"location":"haphpipe_userguide/#installing-haphpipe_1","text":"insert from students","title":"Installing HAPHPIPE"},{"location":"haphpipe_userguide/#activating-haphpipe_1","text":"insert from students","title":"Activating HAPHPIPE"},{"location":"haphpipe_userguide/#haphpipe-suite_2","text":"insert from students","title":"HAPHPIPE suite"},{"location":"haphpipe_userguide/#hp_reads_2","text":"sample_reads trim_reads join_reads ec_reads","title":"hp_reads"},{"location":"haphpipe_userguide/#hp_assemble_2","text":"assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly","title":"hp_assemble"},{"location":"haphpipe_userguide/#hp_haplotype_2","text":"predict_haplo ph_parser","title":"hp_haplotype"},{"location":"haphpipe_userguide/#hp_annotate_2","text":"pairwise_align extract_pairwise annotate_from_ref","title":"hp_annotate"},{"location":"haphpipe_userguide/#example-usage_19","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#your-virus-with-both-pipelines-document-all-code-and-explanation_1","text":"","title":"Your virus with both pipelines. Document all code and explanation."},{"location":"haphpipe_userguide/#starting-directory-structure_1","text":"insert from students","title":"Starting directory structure"},{"location":"haphpipe_userguide/#ending-directory-structure_1","text":"insert from students","title":"Ending directory structure"},{"location":"haphpipe_userguide/#helpful-sources_1","text":"bash scripting conda **insert from students**","title":"Helpful sources"},{"location":"haphpipe_userguide/#faq_1","text":"insert from students","title":"FAQ"},{"location":"haphpipe_userguide/#influenza","text":"Data from NCBI bioproject: PRJNA506454 with associated article . Brief description of the paper and data: insert from students","title":"Influenza"},{"location":"haphpipe_userguide/#quick-start_3","text":"","title":"Quick start"},{"location":"haphpipe_userguide/#miniconda-and-bioconda_2","text":"Step 1. Installing conda . wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh Step 2. Setting up conda channels . conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge","title":"Miniconda and Bioconda"},{"location":"haphpipe_userguide/#downloading-data_2","text":"This is showing how to load miniconda on GW's HPC, Colonial One, which is how undergrads in CBI work on data. module use /groups/cbi/shared/modulefiles module load miniconda3/4.3.27.1 Creating a new conda environment to pull data from SRA. conda create -n fastqdump sra-tools conda activate fastqdump Downloading SRA data. This pulls the 20 random accessions from the SRA list, and only pulls 20,000 reads from SRA data. We pulled randomly, because the study had two sets of influenza types sequenced, and we wanted to pull from both, but randomly This code says for each accession in the accession list, sort them randomly (the -R option applied in sort , and then take the first 20 accession numbers from that randomly sorted list. For each of these 20 accession numbers, pull 20,000 reads from the SRA data and put the output read files into the accession folder. Then deactive the conda environment used to pull these SRA data. for acc in $(cat SraAccList.txt | sort -R | head -n 20); do mkdir -p $acc fastq-dump --outdir $acc --split-files -N 10001 -X 30000 $acc done # deactivate the conda environment now that you are done downloading data conda deactivate","title":"Downloading data"},{"location":"haphpipe_userguide/#installing-haphpipe_2","text":"insert from students","title":"Installing HAPHPIPE"},{"location":"haphpipe_userguide/#activating-haphpipe_2","text":"insert from students","title":"Activating HAPHPIPE"},{"location":"haphpipe_userguide/#haphpipe-suite_3","text":"insert from students","title":"HAPHPIPE suite"},{"location":"haphpipe_userguide/#hp_reads_3","text":"sample_reads trim_reads join_reads ec_reads","title":"hp_reads"},{"location":"haphpipe_userguide/#hp_assemble_3","text":"assemble_denovo assemble_amplicons assemble_scaffold align_reads call_variants vcf_to_consensus refine_assembly finalize_assembly","title":"hp_assemble"},{"location":"haphpipe_userguide/#hp_haplotype_3","text":"predict_haplo ph_parser","title":"hp_haplotype"},{"location":"haphpipe_userguide/#hp_annotate_3","text":"pairwise_align extract_pairwise annotate_from_ref","title":"hp_annotate"},{"location":"haphpipe_userguide/#example-usage_20","text":"","title":"Example usage"},{"location":"haphpipe_userguide/#your-virus-with-both-pipelines-document-all-code-and-explanation_2","text":"","title":"Your virus with both pipelines. Document all code and explanation."},{"location":"haphpipe_userguide/#starting-directory-structure_2","text":"insert from students","title":"Starting directory structure"},{"location":"haphpipe_userguide/#ending-directory-structure_2","text":"insert from students","title":"Ending directory structure"},{"location":"haphpipe_userguide/#helpful-sources_2","text":"bash scripting conda **insert from students**","title":"Helpful sources"},{"location":"haphpipe_userguide/#faq_2","text":"insert from students","title":"FAQ"},{"location":"haphpipe_userguide/#-_3","text":"","title":"---"},{"location":"haphpipe_userguide/#advanced-usage","text":"individual modules + making your own pipelines w/ bash in advanced usage","title":"Advanced Usage"},{"location":"haphpipe_userguide/#-_4","text":"","title":"---"},{"location":"haphpipe_userguide/#file-extension-table","text":"Module Input Input Format Output Output File Names sample_reads FASTQ file(s) .fastq.gz or .fastq or .fq Subampled FASTQ file(s) sample_1.fastq sample_2.fastq trim_reads FASTQ file(s) .fastq.gz or .fastq or .fq Trimmed FASTQ file(s) and summary from Trimmomatic text file trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out join_reads FASTQ file(s) .fastq.gz or .fastq or .fq FASTQ files for joined reads and unjoined reads joined.fastq notjoined_1.fastq notjoined_2.fastq ec_reads FASTQ file(s) .fastq.gz or .fastq or .fq Error corrected FASTQ file(s) corrected_1.fastq corrected_2.fastq corrected_U.fastq assemble_denovo FASTQ file(s) .fastq.gz or .fastq or .fq De novo assembled contigs FASTA file and de novo summary text file denovo_contigs.fna denovo_summary.txt assemble_amplicons FASTA files and GTF file .fna or .fasta or .fa and .gtf FASTA file with assembled amplicons amplicon_assembly.fna assemble_scaffold FASTA files .fna or .fasta or .fa FASTA files with scaffolded and aligned sequences and FASTA file with assembled amplicons scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out align_reads FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa Aligned BAM file and Bowtie2 alignment output summary text file aligned.bam aligned.bt2.out call_variants BAM and FASTA file .bam and .fna or .fasta or .fa VCF file with variants variants.vcf.gz vcf_to_consensus VCF file .vcf FASTA file with consensus sequence consensus.fna refine_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with refined consensus sequence refined.fna finalize_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with final refined consensus sequence and final BAM file with reads aligned to final FASTA file and VCF file with variants relative to final.fna final.fna and final.bam and final.vcf.gz predict_haplo FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa PredictHaplo's fasta-like output file best.fa ph_parser PredictHaplo's FAS output file .fas Summary text file with haplotype diversity statistics and FASTA file with haplotype sequences ph_summary.txt and ph_haplotypes.fna pairwise_align FASTA files and GTF file .fna or .fasta or .fa and .gtf JSON file pairwise_aligned.json extract_pairwise JSON file from pairwise_align output .json FASTA output with region extracted to standard out stdout.fasta annotate_from_ref JSON file from pairwise_align output and GTF file .json and .gtf","title":"File extension table"},{"location":"haphpipe_userguide/#-_5","text":"","title":"---"},{"location":"haphpipe_userguide/#helpful-resources","text":"Conda Bioconda Bioconda channels Bash Command line tutorial List of bash commands Bash scripting tutorial Additional scripting help: linuxconfig.org flaviocopesc.com ryanstutorials.net NGS overview: NYU resource Accessing on a PC using a virtual machine Guide to options VirtualBox","title":"Helpful resources"},{"location":"haphpipe_userguide/#-_6","text":"","title":"---"},{"location":"haphpipe_userguide/#faq_3","text":"what is directory structure?","title":"FAQ"},{"location":"haphpipe_userguide/#-_7","text":"","title":"---"},{"location":"haphpipe_userguide/#related-software","text":"","title":"Related software"},{"location":"help/","text":"Conda Bioconda Bioconda channels Bash Command line tutorial List of bash commands Bash scripting tutorial Additional scripting help: linuxconfig.org flaviocopesc.com ryanstutorials.net NGS overview: NYU resource Accessing on a PC using a virtual machine Guide to options VirtualBox","title":"Helpful Resources"},{"location":"help/#conda","text":"Bioconda Bioconda channels","title":"Conda"},{"location":"help/#bash","text":"Command line tutorial List of bash commands Bash scripting tutorial Additional scripting help: linuxconfig.org flaviocopesc.com ryanstutorials.net","title":"Bash"},{"location":"help/#ngs-overview","text":"NYU resource","title":"NGS overview:"},{"location":"help/#accessing-on-a-pc-using-a-virtual-machine","text":"Guide to options VirtualBox","title":"Accessing on a PC using a virtual machine"},{"location":"home/","text":"HAPHPIPE: HA plotype and PH ylodynamics pipeline for viral assembly, population genetics, and phylodynamics.","title":"Home"},{"location":"home/#haphpipe-haplotype-and-phylodynamics-pipeline-for-viral-assembly-population-genetics-and-phylodynamics","text":"","title":"HAPHPIPE: HAplotype and PHylodynamics pipeline for viral assembly, population genetics, and phylodynamics."},{"location":"hp_annotate/","text":"hp_annotate includes stages to annotate consensus sequence(s). Use -h after any command for a list of options. pairwise_align Apply correct coordinate system to final sequence(s) to facilitate downstream analyses. Input is the final sequence file in FASTA format, a reference sequence in FASTA format, and a reference GFT file. Output is a JSON file to be used in extract_pairwise . Usage: haphpipe pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: extract_pairwise Extract sequence regions from the pairwise alignment produced in pairwise_align . Input is the JSON file from pairwise_align . Output is either an unaligned nucleotide FASTA file, an aligned nucleotide FASTA file, an amino acid FASTA file, an amplicon GTF file, or a tab-separated values (TSV) file (default: nucleotide FASTA with regions of interest from GTF file used in pairwise_align ). Usage: haphpipe extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] (or): hp_extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False). Example usage: annotate_ from_ref Annotate consensus sequence from reference annotation. Input is JSON file from pairwise_align and reference GTF file. Usage: haphpipe annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Example usage:","title":"Annotate"},{"location":"hp_annotate/#pairwise_align","text":"Apply correct coordinate system to final sequence(s) to facilitate downstream analyses. Input is the final sequence file in FASTA format, a reference sequence in FASTA format, and a reference GFT file. Output is a JSON file to be used in extract_pairwise . Usage: haphpipe pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_pairwise_align [SETTINGS] --amplicons_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"pairwise_align"},{"location":"hp_annotate/#extract_pairwise","text":"Extract sequence regions from the pairwise alignment produced in pairwise_align . Input is the JSON file from pairwise_align . Output is either an unaligned nucleotide FASTA file, an aligned nucleotide FASTA file, an amino acid FASTA file, an amplicon GTF file, or a tab-separated values (TSV) file (default: nucleotide FASTA with regions of interest from GTF file used in pairwise_align ). Usage: haphpipe extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] (or): hp_extract_pairwise [OPTIONS] [SETTINGS] --align_json JSON [--outdir] Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False). Example usage:","title":"extract_pairwise"},{"location":"hp_annotate/#annotate_-from_ref","text":"Annotate consensus sequence from reference annotation. Input is JSON file from pairwise_align and reference GTF file. Usage: haphpipe annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_annotate_from_ref [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Example usage:","title":"annotate_ from_ref"},{"location":"hp_assemble/","text":"Stages in hp_assemble are designed to construct consensus sequence(s). Input reads (in FASTQ format) are assembled using either denovo assembly or reference-based alignment. Resulting consensus can be further refined. Use -h after any command for a list of options. assemble_denovo Assemble reads via de novo assembly using SPAdes ( documentation ). Input is reads in FASTQ format. Output is contigs in FNA format. Usage: haphpipe assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: assemble_amplicons Assemble contigs from de novo assembly using both a reference sequence and amplicon regions with MUMMER 3+ ( documentation ). Input is contigs and reference sequence in FASTA format and amplicon regions in GTF format. Usage: haphpipe assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: assemble_scaffold Scaffold contigs against a reference sequence with MUMMER 3+ ( documentation ). Input is contigs in FASTA format and reference sequence in FASTA format. Output is scaffold assembly, alligned scaffold, imputed scaffold, and padded scaffold in FASTA format. Usage: haphpipe assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] (or): hp_assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: align_reads Map reads to reference sequence (instead of running de novo assembly) using Bowtie2 ( documentation ) and Picard ( documentation ). Input is reads in FASTQ format and reference sequence in FASTA format. Usage: haphpipe align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: call_variants Variant calling from alignment using GATK ( documentation ). Input is alignment file in BAM format and reference sequence in FASTA format (either reference from reference-based assembly or consensus final sequence from de novo assembly). Output is a Variant Call File (VCF) format file. Usage: haphpipe call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] (or): hp_call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: vcf_to_consensus Generate a consensus sequence from a VCF file. Input is a VCF file. Output is the consensus sequence in FASTA format. Usage: haphpipe vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] (or): hp_vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage: refine_assembly Map reads to a denovo assembly or reference alignment. Assembly or alignment is iteratively updated. Input is reads in FASTQ format and reference sequence (assembly or reference alignment) in FASTA format. Output is refined assembly in FASTA format. Usage: haphpipe refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: finalize_assembly Finalize consensus, map reads to consensus, and call variants. Input is reads in FASTQ format and reference sequence in FASTA format. Output is finalized reference sequence, alignment, and variants (in FASTA, BAM, and VCF formats, respectively). Usage: haphpipe finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"Assemble"},{"location":"hp_assemble/#assemble_denovo","text":"Assemble reads via de novo assembly using SPAdes ( documentation ). Input is reads in FASTQ format. Output is contigs in FNA format. Usage: haphpipe assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_assemble_denovo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"assemble_denovo"},{"location":"hp_assemble/#assemble_amplicons","text":"Assemble contigs from de novo assembly using both a reference sequence and amplicon regions with MUMMER 3+ ( documentation ). Input is contigs and reference sequence in FASTA format and amplicon regions in GTF format. Usage: haphpipe assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] (or): hp_assemble_amplicons [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA --ref_gtf GTF [--outdir] Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"assemble_amplicons"},{"location":"hp_assemble/#assemble_scaffold","text":"Scaffold contigs against a reference sequence with MUMMER 3+ ( documentation ). Input is contigs in FASTA format and reference sequence in FASTA format. Output is scaffold assembly, alligned scaffold, imputed scaffold, and padded scaffold in FASTA format. Usage: haphpipe assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] (or): hp_assemble_scaffold [OPTIONS] [SETTINGS] --contigs_fa FASTA --ref_fa FASTA [--outdir] Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"assemble_scaffold"},{"location":"hp_assemble/#align_reads","text":"Map reads to reference sequence (instead of running de novo assembly) using Bowtie2 ( documentation ) and Picard ( documentation ). Input is reads in FASTQ format and reference sequence in FASTA format. Usage: haphpipe align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_align_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"align_reads"},{"location":"hp_assemble/#call_variants","text":"Variant calling from alignment using GATK ( documentation ). Input is alignment file in BAM format and reference sequence in FASTA format (either reference from reference-based assembly or consensus final sequence from de novo assembly). Output is a Variant Call File (VCF) format file. Usage: haphpipe call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] (or): hp_call_variants [OPTIONS] [SETTINGS] --aln_bam BAM --ref_fa FASTA [--outdir] Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"call_variants"},{"location":"hp_assemble/#vcf_to_consensus","text":"Generate a consensus sequence from a VCF file. Input is a VCF file. Output is the consensus sequence in FASTA format. Usage: haphpipe vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] (or): hp_vcf_to_consensus [OPTIONS] [SETTINGS] --vcf FASTQ [--outdir] [--sampidx] Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage:","title":"vcf_to_consensus"},{"location":"hp_assemble/#refine_assembly","text":"Map reads to a denovo assembly or reference alignment. Assembly or alignment is iteratively updated. Input is reads in FASTQ format and reference sequence (assembly or reference alignment) in FASTA format. Output is refined assembly in FASTA format. Usage: haphpipe refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_refine_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Reference fasta file. --outdir Output directory (default: False). Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"refine_assembly"},{"location":"hp_assemble/#finalize_assembly","text":"Finalize consensus, map reads to consensus, and call variants. Input is reads in FASTQ format and reference sequence in FASTA format. Output is finalized reference sequence, alignment, and variants (in FASTA, BAM, and VCF formats, respectively). Usage: haphpipe finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] (or): hp_finalize_assembly [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ --ref_fa FASTA [--outdir] Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage:","title":"finalize_assembly"},{"location":"hp_haplotype/","text":"hp_haplotype includes haplotype assembly stages. HAPHPIPE implements PredictHaplo ( paper ), although other haplotype reconstruction programs can be utilized outside of HAPHPIPE using the final output of HAPHPIPE, typically with the final consensus sequence (FASTA) file, reads (raw, trimmed, and/or corrected), and/or final alignment (BAM) file as input. Use -h after any command for a list of options. predict_haplo Haplotype identification with PredictHaplo. Input is reads in FASTQ format and and reference sequence in FASTA format. Output is the longest global haplotype file and corresponding HTML file. Note: PredictHaplo must be installed separately before running this stage. Usage: haphpipe predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] (or): hp_ predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] Output files: best.fa Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --ref_fa Reference sequence used to align reads (Fasta). --interval_txt File with intervals to perform haplotype reconstruction. --outdir Output directory (default: current directory). Options: Option Description --min_readlength Minimum read length passed to PredictHaplo (default: 36). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage ph_parser Returns PredictHaplo output as a correctly formatted FASTA file. Input is the output file from predict_haplo (longest global .fas file). Output is a correctly formatted FASTA file. Usage: haphpipe ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Output files: ph_summary.txt ph_haplotypes.fna Input/Output Arguments: Option Description --haplotypes_fa Haplotype file created by PredictHaplo. --outdir Output directory (default: current directory). Options: Option Description --prefix Prefix to add to sequence names. --keep_gaps Do not remove gaps from alignment (default: False). Settings: Option Description --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage: By default, PredictHaplo outputs their own unique version of a fasta file. It includes the frequency, some information regarding their unqiue overlapping scores, and their unique confidence scores. This file is always named PH#.best_#_#.fas , where the first number is the reconstructed haplotype number and the next numbers are the start and end of the longest haplotype reconstructed by PredictHaplo. $ cat PH01.best_1_1208.fas reconstructed_0 ;Freq:0.190638 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~n7~~~y~~~~~t~~~i~jjk~~zz ;~~~~{~~~~~N{~{~Sx~~~~~~z~K~F~~~~~~~y~~~~~~~|~~F~wx|~~{~~|~~s |]~~~~~~ ;~m~kj|{|v~{|_`~~~z~~~~~~~jy{y~~~~~a~__~~|~~~~~{wXZ~}~~~qm~xV~~~~~~~}~ ;Q~}~y||~~~}}~~~z~~~~~~{}A~}b|~~u~~|}}|~}}z~}bx~~n||~~||{~}~~d}~bz~~~} ;|~}}~~~}~~~{|}}g{~~~}~r~}}~~~~u~~{kx{~}~}~|~}~}{}~}~}||~~~~[~}~}}~~~~ ;~~}~~~U||U}~|}}~~}}~~~~}u~b|}~w~~~~~{}|wv~}Dxzp{|}~@~~P~}~}~V~~z}~|ry ;q~}|}~}~~}t~o~}~f}~~}{~~~}~{~~~~~~~}~~}~~|~~~M~~}~}x~}c~}^v~~~yzA~}~} ;y}~z}~~~~~~~~~{z~~}~~~}~{}~~~~~}~~~~~~~|~~v~~}~~|y~]|{~||~~~~~~~~||~~ ;Y||~~|Q~|~~~|~~~~~|~~~z~~z~{{{y~~~~~~~~~~w{{~wz|~Z|~z|~~}p|~~|}}~~x}} ;z}~}}|a|}}}}{}|~~}}~}}~}~{~|~}}~}{}|}|}}}~|}}}}{}}}|}}|}|}}}|}}}}~}}} ;||}}}}{}}~}~}}}}}}}}}}}~}}}}}}}}}}}}}}}}}y}~}}}}}}}}}}~|}}}}|}}}}|}}} ;}}}}}}}}|}}}}}}}}~}}}}}}|}}}}}}}}|}}}}}|}}}}|~|}}}}{}}}}}}}}}}}}}}}}} ;}}=}}}{}}}}}}}}}}}}}}}}}}}}}}}}~||}}|~}}}}}{}}}}}|}}|}}}}}}}}}}}}}|}} ;|}~}}}}|}}}}}}}}|}|~J}}}}}}~}}}}}}}}}}}}}}}}}}}}|}}`~}}}}|}}}}}}}}}}~ ;|}}}}}}}}}}}~}}}|}}}}}}}}}}|}}}}}}}}}}}t}}{}`}}}}}}|}~}~}|~}}}|k}}}}} ;|}|~}}|}}~}}~}|}}z}}}}}}}}}}}}}}~}}~}}}~~}|}}}~}}}}}}}}~}~}}||~~}~z}} ;~~}~}||~|~}|{}||~|z~~||}~|~}}|}~~}|}}~}}|}z~~~~{~}{}~y~~~~~{|}}~~|y~~ ;~|~~||~~~~~~~|n~~{~~~~~~~~~~~~~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 ;Freq:0.294104 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~z~~~~~~~~~|~y~~~~u}|~~~~~}}~~~~~~~ya~|~~}}~~~y~~~j~YXH~~s~ ;~~~~z~~|~~b|}^}xZ}}~}z~t~r~{}~}x}}yb}~~~}~}u~~}~gu|}}{~|}}~ozsw}|}}h~ ;|l}v|^][t}zz}vw}}s}}}}~v}|~|~~}}}~~}}}}}~}}}}}}zo\\}}}~}vn}iv}}}}}}}}} ;v}}~|u}}}}}}}}}|}}}}}}|}^}}[}~}r}}}{|}}|t|}}{z}}pz}}{}}}}}}}v~}y|~}}} ;}}}}~}}~}}}tz}}`}}}~}}q}}}}}~}y}}|r||}}}}~}}~}}{}}}}}}}}}}}y~}}}}t}}} ;}}}}}}{|}|}}{r}}}}tv~}}}t}m|~}h}}}}}v}}qt}|y|{|u~}}|}~_}~|~~|}~|}~}|e ;Y}~}}~}}~}v}t}}}j}}~}}}~}}~|}}}}|}}|}}}~}}}}};}}~}}x}}|}}yu}}}wy`}|~~ ;{}}x}}}}}~}}}~{v}}}}}{}~}}~}~}}|}}}}}}}}}}u}}y~~{g}L}}}}}|~}{~|}|}|}} ;l}}}}{_}}}}~z~}|}~~|~~x|~}~z~~|~}~~~}~~~}y}~~|k}}Pf}w~~~~T}}}F~~}~z}{ ;{~|}|zZ~s~|}r~}}~~|}}}}}~|}}}}n}}}~}}}}~}}}}}}}}}}}|~}}}}}}~~}}~~~~~} ;N}}}}}|~}}~}}}}{}}}~}}|~~|}|}}}~|}~}}}}}}D}~}}}}}}}}}}}}}}}}|}}z}|}}} ;}k}}}}}}}}}}}}}}}}}}}|}}}}}|}}}}}|}}}}}|}}}}|~{~}}}G}~}}}}}~}}}}}}}}} ;}}h}}~|}|}}}}}}}}}}}}}}}}}}}}}}}}{}}|}}}}|~|}}}}}}}M}}}}}}}~}}}}}}}}} ;}}~|}}}}}~~~}}}~}}|}g}}}}}}}}~|}}}}}}}}}}}}}}}}}|}~t~}|}}}}}}}||~}}}} ;|}}}}~}}}}}}~}}}gi}}~}}}}}}}}}}}}|}}~}}g}~}}v}}}}}|{}}}}}}~}}~|e}}}}} ;}}|}}~}~}~}}~}|~}|}~|||}}}}|~}}~}}}}}}}}|}}~}}~}|~}|y~}~}}}}}|}}~~}~} ;}}~}~}|~}}}~}}}}~}{}}~}}~}}}||~~}||~}x|}{~|}|~~|~}}}|{~}}~}{}}||~}}}~ ;|~}~}}}~|}}~~|,~~~~~~~~~~~~~~m~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 ;Freq:0.515259 ;Overlap quality scores (5,10):4,4 ;Confidence scores ;~~~~~~~w~~zz~~~~z~~w~|wy~|~~{|~~|~~~~~~~~}~{~hD~~~}|~|}}t~~_;~tue}}S} ;~}~~p}}l}~P}}ZlvL~z}}h~g~A~x}}}s}}{S~}~}}}}l}~|}SOq}}q}w}}~i\\pz~w~~z~ ;}7~|vzUu4|smtgm}~W}}~~}r}n`f`}{PZLSI:Vs_V_}}}}_ db}}}}}CQ}YJ}t}}}~}}} ;T}}~|}}}}}}}~}}k}}}}}}q}L}}]}}}L}}}tt|~}{q}}{M}lAIu}}}s{}}}~y~}st}|}} ;z}}}}|}}}}}{q|}Z}}}}}}P~}|}|}}E}}cLbi}vu}}|}}|}g}}}}}}|}~}~{}~}|}{}}} ;}~}|}}}{{|~}pp}~~~{|}}~}[yEx}}\\}}}{}N}uoK}}pauSy}}}v~~J}}q}}v~}c}~}\\i ;]|}}~}|}~}r}Y}}}B}}~||~}}}}{}}}|}|~|}~~~~}}~{w}{}~|R|}s|}k{~}}}ra}q}} ;o}}d}~}}}}}~}}|X~}}~}e}}}}}}}|}y|}}}}~}|~}c~~b~~nL~a}}}}}~}}m}}~{}}}} ;g}}}}uLm~l}}`~|n}}~}}|d~~y~u}|tz~~~~|}}~~t}}}tx}|Tu~v}}~}^|~~w~|~}m{} ;u}}}|w;}{}{}r}||}}z|}|~|}z}||}y}}}~}}}|}}~}}}|}y}}}}}}}~}||}}}}}}~}}| ;v{}|}}{}}}|~|}}|}}}}}}}}}}|}}}}}|}~}}}}}}p}}||}}}}}~}}}{}}}}}}}z}}}}} ;}|}}~}}}|}}}}}}}}}}}}}}}}}}}}}}|}||}}|}|}}}}|}|}}}}u}}}}}}}}}}}}}}}}} ;}}g}}}{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}}}}|}m}}}}}}}}}}}}}}}}} ;}}}}}}}}}}}}}}}}}}|}i}}}}}}}}}}|}}}}}}}}}}}}}}}}}}}H}}}}}}}}}|}{}}}}} ;|}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}|}H}}}}}}}}}}}}}}}}}}u}}}}} ;}}}}}}}}}}}}}}}}}z}}}}}}}}}}}}}}}}|}}}|}}}}}}}}}|}}}}}}}}}}}}|}}}}|}} ;}}}}}}}}}}}}||}|}}|}}}}}}|}}|}}}~}|}|}}}|}{}}}}|}}}}|{|}}}}x||}}}|{}} ;}}}}}}}~}}~}~|n}~}}}}}~}}~~|~~~y~, ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC ph_parser takes this output and creates a proper fasta file with each resontructed haplotype and a text file that has the hpalotype diversity estimate. $ cat ph_summary.txt PH_num_hap 3 PH_hap_diversity 0.611668153059 PH_seq_len 1208 $ cat ph_haplotypes.fna reconstructed_0 Freq=0.190638 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 Freq=0.294104 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 Freq=0.515259 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC","title":"Haplotype"},{"location":"hp_haplotype/#predict_haplo","text":"Haplotype identification with PredictHaplo. Input is reads in FASTQ format and and reference sequence in FASTA format. Output is the longest global haplotype file and corresponding HTML file. Note: PredictHaplo must be installed separately before running this stage. Usage: haphpipe predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] (or): hp_ predict_haplo [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --ref_fa FASTA --interval_txt [TXT] [--outdir] Output files: best.fa Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --ref_fa Reference sequence used to align reads (Fasta). --interval_txt File with intervals to perform haplotype reconstruction. --outdir Output directory (default: current directory). Options: Option Description --min_readlength Minimum read length passed to PredictHaplo (default: 36). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage","title":"predict_haplo"},{"location":"hp_haplotype/#ph_parser","text":"Returns PredictHaplo output as a correctly formatted FASTA file. Input is the output file from predict_haplo (longest global .fas file). Output is a correctly formatted FASTA file. Usage: haphpipe ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] (or): hp_ph_parser [OPTIONS] [SETTINGS] --haplotypes_fa best.fas [--outdir] Output files: ph_summary.txt ph_haplotypes.fna Input/Output Arguments: Option Description --haplotypes_fa Haplotype file created by PredictHaplo. --outdir Output directory (default: current directory). Options: Option Description --prefix Prefix to add to sequence names. --keep_gaps Do not remove gaps from alignment (default: False). Settings: Option Description --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. Example usage: By default, PredictHaplo outputs their own unique version of a fasta file. It includes the frequency, some information regarding their unqiue overlapping scores, and their unique confidence scores. This file is always named PH#.best_#_#.fas , where the first number is the reconstructed haplotype number and the next numbers are the start and end of the longest haplotype reconstructed by PredictHaplo. $ cat PH01.best_1_1208.fas reconstructed_0 ;Freq:0.190638 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~n7~~~y~~~~~t~~~i~jjk~~zz ;~~~~{~~~~~N{~{~Sx~~~~~~z~K~F~~~~~~~y~~~~~~~|~~F~wx|~~{~~|~~s |]~~~~~~ ;~m~kj|{|v~{|_`~~~z~~~~~~~jy{y~~~~~a~__~~|~~~~~{wXZ~}~~~qm~xV~~~~~~~}~ ;Q~}~y||~~~}}~~~z~~~~~~{}A~}b|~~u~~|}}|~}}z~}bx~~n||~~||{~}~~d}~bz~~~} ;|~}}~~~}~~~{|}}g{~~~}~r~}}~~~~u~~{kx{~}~}~|~}~}{}~}~}||~~~~[~}~}}~~~~ ;~~}~~~U||U}~|}}~~}}~~~~}u~b|}~w~~~~~{}|wv~}Dxzp{|}~@~~P~}~}~V~~z}~|ry ;q~}|}~}~~}t~o~}~f}~~}{~~~}~{~~~~~~~}~~}~~|~~~M~~}~}x~}c~}^v~~~yzA~}~} ;y}~z}~~~~~~~~~{z~~}~~~}~{}~~~~~}~~~~~~~|~~v~~}~~|y~]|{~||~~~~~~~~||~~ ;Y||~~|Q~|~~~|~~~~~|~~~z~~z~{{{y~~~~~~~~~~w{{~wz|~Z|~z|~~}p|~~|}}~~x}} ;z}~}}|a|}}}}{}|~~}}~}}~}~{~|~}}~}{}|}|}}}~|}}}}{}}}|}}|}|}}}|}}}}~}}} ;||}}}}{}}~}~}}}}}}}}}}}~}}}}}}}}}}}}}}}}}y}~}}}}}}}}}}~|}}}}|}}}}|}}} ;}}}}}}}}|}}}}}}}}~}}}}}}|}}}}}}}}|}}}}}|}}}}|~|}}}}{}}}}}}}}}}}}}}}}} ;}}=}}}{}}}}}}}}}}}}}}}}}}}}}}}}~||}}|~}}}}}{}}}}}|}}|}}}}}}}}}}}}}|}} ;|}~}}}}|}}}}}}}}|}|~J}}}}}}~}}}}}}}}}}}}}}}}}}}}|}}`~}}}}|}}}}}}}}}}~ ;|}}}}}}}}}}}~}}}|}}}}}}}}}}|}}}}}}}}}}}t}}{}`}}}}}}|}~}~}|~}}}|k}}}}} ;|}|~}}|}}~}}~}|}}z}}}}}}}}}}}}}}~}}~}}}~~}|}}}~}}}}}}}}~}~}}||~~}~z}} ;~~}~}||~|~}|{}||~|z~~||}~|~}}|}~~}|}}~}}|}z~~~~{~}{}~y~~~~~{|}}~~|y~~ ;~|~~||~~~~~~~|n~~{~~~~~~~~~~~~~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 ;Freq:0.294104 ;Overlap quality scores (5,10):1,1 ;Confidence scores ;~~~~~~~~z~~~~~~~~~|~y~~~~u}|~~~~~}}~~~~~~~ya~|~~}}~~~y~~~j~YXH~~s~ ;~~~~z~~|~~b|}^}xZ}}~}z~t~r~{}~}x}}yb}~~~}~}u~~}~gu|}}{~|}}~ozsw}|}}h~ ;|l}v|^][t}zz}vw}}s}}}}~v}|~|~~}}}~~}}}}}~}}}}}}zo\\}}}~}vn}iv}}}}}}}}} ;v}}~|u}}}}}}}}}|}}}}}}|}^}}[}~}r}}}{|}}|t|}}{z}}pz}}{}}}}}}}v~}y|~}}} ;}}}}~}}~}}}tz}}`}}}~}}q}}}}}~}y}}|r||}}}}~}}~}}{}}}}}}}}}}}y~}}}}t}}} ;}}}}}}{|}|}}{r}}}}tv~}}}t}m|~}h}}}}}v}}qt}|y|{|u~}}|}~_}~|~~|}~|}~}|e ;Y}~}}~}}~}v}t}}}j}}~}}}~}}~|}}}}|}}|}}}~}}}}};}}~}}x}}|}}yu}}}wy`}|~~ ;{}}x}}}}}~}}}~{v}}}}}{}~}}~}~}}|}}}}}}}}}}u}}y~~{g}L}}}}}|~}{~|}|}|}} ;l}}}}{_}}}}~z~}|}~~|~~x|~}~z~~|~}~~~}~~~}y}~~|k}}Pf}w~~~~T}}}F~~}~z}{ ;{~|}|zZ~s~|}r~}}~~|}}}}}~|}}}}n}}}~}}}}~}}}}}}}}}}}|~}}}}}}~~}}~~~~~} ;N}}}}}|~}}~}}}}{}}}~}}|~~|}|}}}~|}~}}}}}}D}~}}}}}}}}}}}}}}}}|}}z}|}}} ;}k}}}}}}}}}}}}}}}}}}}|}}}}}|}}}}}|}}}}}|}}}}|~{~}}}G}~}}}}}~}}}}}}}}} ;}}h}}~|}|}}}}}}}}}}}}}}}}}}}}}}}}{}}|}}}}|~|}}}}}}}M}}}}}}}~}}}}}}}}} ;}}~|}}}}}~~~}}}~}}|}g}}}}}}}}~|}}}}}}}}}}}}}}}}}|}~t~}|}}}}}}}||~}}}} ;|}}}}~}}}}}}~}}}gi}}~}}}}}}}}}}}}|}}~}}g}~}}v}}}}}|{}}}}}}~}}~|e}}}}} ;}}|}}~}~}~}}~}|~}|}~|||}}}}|~}}~}}}}}}}}|}}~}}~}|~}|y~}~}}}}}|}}~~}~} ;}}~}~}|~}}}~}}}}~}{}}~}}~}}}||~~}||~}x|}{~|}|~~|~}}}|{~}}~}{}}||~}}}~ ;|~}~}}}~|}}~~|,~~~~~~~~~~~~~~m~~~ ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 ;Freq:0.515259 ;Overlap quality scores (5,10):4,4 ;Confidence scores ;~~~~~~~w~~zz~~~~z~~w~|wy~|~~{|~~|~~~~~~~~}~{~hD~~~}|~|}}t~~_;~tue}}S} ;~}~~p}}l}~P}}ZlvL~z}}h~g~A~x}}}s}}{S~}~}}}}l}~|}SOq}}q}w}}~i\\pz~w~~z~ ;}7~|vzUu4|smtgm}~W}}~~}r}n`f`}{PZLSI:Vs_V_}}}}_ db}}}}}CQ}YJ}t}}}~}}} ;T}}~|}}}}}}}~}}k}}}}}}q}L}}]}}}L}}}tt|~}{q}}{M}lAIu}}}s{}}}~y~}st}|}} ;z}}}}|}}}}}{q|}Z}}}}}}P~}|}|}}E}}cLbi}vu}}|}}|}g}}}}}}|}~}~{}~}|}{}}} ;}~}|}}}{{|~}pp}~~~{|}}~}[yEx}}\\}}}{}N}uoK}}pauSy}}}v~~J}}q}}v~}c}~}\\i ;]|}}~}|}~}r}Y}}}B}}~||~}}}}{}}}|}|~|}~~~~}}~{w}{}~|R|}s|}k{~}}}ra}q}} ;o}}d}~}}}}}~}}|X~}}~}e}}}}}}}|}y|}}}}~}|~}c~~b~~nL~a}}}}}~}}m}}~{}}}} ;g}}}}uLm~l}}`~|n}}~}}|d~~y~u}|tz~~~~|}}~~t}}}tx}|Tu~v}}~}^|~~w~|~}m{} ;u}}}|w;}{}{}r}||}}z|}|~|}z}||}y}}}~}}}|}}~}}}|}y}}}}}}}~}||}}}}}}~}}| ;v{}|}}{}}}|~|}}|}}}}}}}}}}|}}}}}|}~}}}}}}p}}||}}}}}~}}}{}}}}}}}z}}}}} ;}|}}~}}}|}}}}}}}}}}}}}}}}}}}}}}|}||}}|}|}}}}|}|}}}}u}}}}}}}}}}}}}}}}} ;}}g}}}{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}}}}|}m}}}}}}}}}}}}}}}}} ;}}}}}}}}}}}}}}}}}}|}i}}}}}}}}}}|}}}}}}}}}}}}}}}}}}}H}}}}}}}}}|}{}}}}} ;|}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}y}}|}H}}}}}}}}}}}}}}}}}}u}}}}} ;}}}}}}}}}}}}}}}}}z}}}}}}}}}}}}}}}}|}}}|}}}}}}}}}|}}}}}}}}}}}}|}}}}|}} ;}}}}}}}}}}}}||}|}}|}}}}}}|}}|}}}~}|}|}}}|}{}}}}|}}}}|{|}}}}x||}}}|{}} ;}}}}}}}~}}~}~|n}~}}}}}~}}~~|~~~y~, ;EndOfComments ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC ph_parser takes this output and creates a proper fasta file with each resontructed haplotype and a text file that has the hpalotype diversity estimate. $ cat ph_summary.txt PH_num_hap 3 PH_hap_diversity 0.611668153059 PH_seq_len 1208 $ cat ph_haplotypes.fna reconstructed_0 Freq=0.190638 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAATATCTGGCCTTCCCGCAAGGGAAG GCCAGGGAACTTTCCTCAGAGCAGGCTAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGCTTGGGGAA GCAACAACAAAGCCCTCTCAGAAACAGGAGCCAATAGACAAGGAAATGTATCCTTTAACTTCCCTCAGAT CACTCTTTGGCAACGACCCCTTGTCACAATAAAGATAGGGGAGCAACTAAAGGAAGCCCTGTTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAGAATGATAGGGGGAA TCGGGGGTTTTATCAAAGTAAGACAGTATGATCAGATAGCCATAGACATCTGTGGCCATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAAGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGCGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACTAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_1 Freq=0.294104 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCCGCGGCGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAG GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGAAGGACAAGGAAACATATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTTGTTACAATAAAGATAGGGGGGCAGCTAAAGGAAGCTCTATTAGATACA GGAGCAGATGACACAGTATTAGAAGAAATGGATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATTTGTGGACATAAAGTGATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTGAAGCCAGGAATGGATGGCCCAAAGG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATCTGTGCAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGAAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAAAGAACTTAATAAGAGAACTCAGGACTTCTGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAGTCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTACACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AATGTAGCATGACAAAAATCTTAGAACCTTTTAGAAAACAAAATCCAGATATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCTT reconstructed_2 Freq=0.515259 ACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAAATCTGGCCTTCCCACAAGGGAAG GCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTTTGGGGAA GAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAAATGTATCCTTTAGCTTCCCTCAAAT CACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACA GGAGCAGATGATACAGTATTAGAAGAAATGAATTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAA TTGGAGGTTTTATCAAAGTAAAACAGTATGATCAGATACCCATAGAAATCTGTGGACATAAAGCTATAGG TACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACT TTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAG TTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGA AGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAGGAAAAAAGAC AGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCCGGGAAGTCC AATTAGGAATACCACATCCCTCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGC ATATTTTTCAGTTCCCTTAGATGAAGACTTCAGAAAGTATACTGCATTTACCATACCTAGTGTAAACAAT GAGACACCAGGGATTAGGTATCAGTACAATGTGCTTCCACAAGGATGGAAAGGATCACCAGCAATATTCC AAGCTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACAT GGATGATCTGTATGTAGGATCTGACCTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAACTGAGAGAA CATCTGTTGAGGTGGGGGTTTTGCACACCAGACAAGAAACATCAGAAGGAACCTCCATTCCTTTGGATGG GTTATGAACTCCATCCCC","title":"ph_parser"},{"location":"hp_reads/","text":"hp_reads involves cleaning up the raw read sequences, as well as other processing steps. Modules to manipulate reads. Use -h after any command for a list of options. sample_reads Subsample reads using seqtk ( documentation ). Input is reads in FASTQ format. Output is sampled reads in FASTQ format. You do not have to have all read options (i.e., read1, read2 AND unpaired reads). You can have a combination of any of those. Usage: haphpipe sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage: This pulls 1000 reads from these paired end files with a starting seed of 1234. haphpipe sample_reads --fq1 read_1.fastq --fq2 read_2.fastq --nreads 1000 --seed 1234 -- trim_reads Trim reads using Trimmomatic ( documentation ). Input is reads in FASTQ format. Output is trimmed reads in FASTQ format. Usage: haphpipe trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: This trims paired end read files 1 and 2. haphpipe trim_reads --fq1 read_1.fastq --fq2 read_2.fastq -- join_reads Join reads using FLASH ( paper ). Input is reads in FASTQ format. Output is joined reads in FASTQ format. Usage: haphpipe join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] (or): hp_join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: -- ec_reads Error correction using SPAdes ( documentation ). Input is reads in FASTQ format. Output is error-corrected reads in FASTQ format. Remember that HAPHPIPE is intended for Illumina reads, therefore the error correction is based on Illumina sequencing errors. Usage: haphpipe ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage: --","title":"Reads"},{"location":"hp_reads/#sample_reads","text":"Subsample reads using seqtk ( documentation ). Input is reads in FASTQ format. Output is sampled reads in FASTQ format. You do not have to have all read options (i.e., read1, read2 AND unpaired reads). You can have a combination of any of those. Usage: haphpipe sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_sample_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage: This pulls 1000 reads from these paired end files with a starting seed of 1234. haphpipe sample_reads --fq1 read_1.fastq --fq2 read_2.fastq --nreads 1000 --seed 1234 --","title":"sample_reads"},{"location":"hp_reads/#trim_reads","text":"Trim reads using Trimmomatic ( documentation ). Input is reads in FASTQ format. Output is trimmed reads in FASTQ format. Usage: haphpipe trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_trim_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: This trims paired end read files 1 and 2. haphpipe trim_reads --fq1 read_1.fastq --fq2 read_2.fastq --","title":"trim_reads"},{"location":"hp_reads/#join_reads","text":"Join reads using FLASH ( paper ). Input is reads in FASTQ format. Output is joined reads in FASTQ format. Usage: haphpipe join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] (or): hp_join_reads [OPTIONS] [SETTINGS] --fq1 FASTQ --fq2 FASTQ [--outdir] Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). Example usage: --","title":"join_reads"},{"location":"hp_reads/#ec_reads","text":"Error correction using SPAdes ( documentation ). Input is reads in FASTQ format. Output is error-corrected reads in FASTQ format. Remember that HAPHPIPE is intended for Illumina reads, therefore the error correction is based on Illumina sequencing errors. Usage: haphpipe ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] (or): hp_ec_reads [SETTINGS] --fq1 FASTQ --fq2 FASTQ --fqU FASTQ [--outdir] Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False. Example usage: --","title":"ec_reads"},{"location":"inout/","text":"Module Input Input Format Output Output File Names sample_reads FASTQ file(s) .fastq.gz or .fastq or .fq Subampled FASTQ file(s) sample_1.fastq sample_2.fastq trim_reads FASTQ file(s) .fastq.gz or .fastq or .fq Trimmed FASTQ file(s) and summary from Trimmomatic text file trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out join_reads FASTQ file(s) .fastq.gz or .fastq or .fq FASTQ files for joined reads and unjoined reads joined.fastq notjoined_1.fastq notjoined_2.fastq ec_reads FASTQ file(s) .fastq.gz or .fastq or .fq Error corrected FASTQ file(s) corrected_1.fastq corrected_2.fastq corrected_U.fastq assemble_denovo FASTQ file(s) .fastq.gz or .fastq or .fq De novo assembled contigs FASTA file and de novo summary text file denovo_contigs.fna denovo_summary.txt assemble_amplicons FASTA files and GTF file .fna or .fasta or .fa and .gtf FASTA file with assembled amplicons amplicon_assembly.fna assemble_scaffold FASTA files .fna or .fasta or .fa FASTA files with scaffolded and aligned sequences and FASTA file with assembled amplicons scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out align_reads FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa Aligned BAM file and Bowtie2 alignment output summary text file aligned.bam aligned.bt2.out call_variants BAM and FASTA file .bam and .fna or .fasta or .fa VCF file with variants variants.vcf.gz vcf_to_consensus VCF file .vcf FASTA file with consensus sequence consensus.fna refine_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with refined consensus sequence refined.fna finalize_assembly FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa FASTA file with final refined consensus sequence and final BAM file with reads aligned to final FASTA file and VCF file with variants relative to final.fna final.fna and final.bam and final.vcf.gz predict_haplo FASTQ files and FASTA file .fastq.gz or .fastq or .fq and .fna or .fasta or .fa PredictHaplo's fasta-like output file best.fa ph_parser PredictHaplo's FAS output file .fas Summary text file with haplotype diversity statistics and FASTA file with haplotype sequences ph_summary.txt and ph_haplotypes.fna pairwise_align FASTA files and GTF file .fna or .fasta or .fa and .gtf JSON file pairwise_aligned.json extract_pairwise JSON file from pairwise_align output .json FASTA output with region extracted to standard out stdout.fasta annotate_from_ref JSON file from pairwise_align output and GTF file .json and .gtf","title":"Input/Output"},{"location":"install/","text":"HAPHPIPE Installation Instructions HAPHIPE depends on more than a dozen different programs, each of which may itself depend on other programs and libraries. Installing everything separately would be a nightmare, so you should use the package manager \"Bioconda\" to install everything. Bioconda is a popular package manager in the bioinformatics world. See the Helpful Resources section for more information and resources for Bioconda. Here, we will describe where to get Bioconda and how to install it, then how to use Bioconda to install the necessary programs for HAPHPIPE. We will also detail the acquisition and installation of one program, GTAK, that is not handled by Bioconda, and finally the acquisition and installation of HAPHPIPE itself. Here, we describe the procedure for installing HAPHPIPE using the package manager Bioconda (Gr\u00fcning et al. 2018) on the command line. If you are unfamiliar with Bioconda, please see for installation and channel setup. HAPHPIPE is available here and is written in Python 3.7.2 coding language. The installation process begins with the creation of a conda environment that installs the necessary dependencies required by HAPHPIPE. Once the conda environment has been created, it can be activated for use with the command conda activate haphpipe. Due to license restrictions, Bioconda cannot distribute and install GATK (McKenna et al. 2010; Van der Auwera et al. 2013; Poplin et al. 2018) directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute (link) . You can then install HAPHPIPE using the single command pip install git+git://github.com/gwcbi/haphpipe.git , which pulls the repository from Github. 1. Install conda Download the conda package: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh 2. Set up conda channels These need to be put in as a command in the order they come, as this sets the priority for where packages are pulled from. Therefore, in this order, conda-forge is top priority and explored first when downloading a program. conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge 3. Create a conda environment with the following dependencies conda create -n haphpipe \\ python=3.7 \\ future \\ pyyaml \\ biopython \\ seqtk \\ bowtie2 \\ bwa \\ flash \\ freebayes \\ mummer \\ picard \\ trimmomatic \\ samtools=1.9 \\ gatk=3.8 \\ spades \\ blast \\ sierrapy 4. Activate the environment conda activate haphpipe 5. Install GATK Due to license restrictions, bioconda cannot distribute and install GATK directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute: https://software.broadinstitute.org/gatk/download/archive . Register the package using gatk3-register: gatk3-register /path/to/GenomeAnalysisTK-3.8-0-ge9d806836.tar.bz2 This will copy GATK into your conda environment. Alternatively, GATK may be installed directly on the command line with the following commands: mkdir -p /path/to/gatk_dir wget -O - 'https://software.broadinstitute.org/gatk/download/auth?package=GATK-archive version=3.6-0-g89b7209' | tar -xjvC /path/to/gatk_dir gatk3-register /path/to/gatk_dir/GenomeAnalysisTK.jar NOTE: HAPHPIPE was developed and tested using GATK 3.8. 6. Install HAPHPIPE pip install git+git://github.com/gwcbi/haphpipe.git Upon completion of the installation, you can test it to ensure the repository has been installed completely and correctly by running haphpipe -h (in quick start). Once HAPHPIPE is installed and performing correctly, there is no need to install it again; simply activate the conda environment when needed by executing conda activate haphpipe . If a new version is released in the future, HAPHPIPE can be updated by running the command line pip install --upgrade git+git://github.com/gwcbi/haphpipe.git . At any point, the -h option that follows any HAPHPIPE stage will output a help message that provides a description of the stage and the desired input(s) and output(s). PredictHaplo Installation Instructions Users are required to download PredictHaplo on their own computing system prior to running any of the haplotype stages ( hp_predict_haplo and hp_ph_parser ). Here is how the GW CBI team installed PredictHaplo onto our HPC, which has a slurm scheduling system and uses Lua module files. We cannot help with the installation of this software, but have provided the code that we used here to install PredictHaplo onto our system. Please see their website for contact information if needed. This module loads predicthaplo onto GWU's HPC - Colonial One. See https://bmda.dmi.unibas.ch/software.html cd /path/to/modules/predicthaplo # use gcc 4.9.4, add blas and lapack to library path module load gcc/4.9.4 module load blas/gcc/64 module load lapack/gcc/64 # download source cd archive wget https://bmda.dmi.unibas.ch/software/PredictHaplo-Paired-0.4.tgz cd .. # unzip source and change directory name tar xfvz archive/PredictHaplo-Paired-0.4.tgz mv PredictHaplo-Paired-0.4 0.4 cd 0.4 # install scythestat tar xfvz scythestat-1.0.3.tar.gz cd scythestat-1.0.3 ./configure --prefix=/path/to/modules/predicthaplo/0.4/NEWSCYTHE make install cd .. # compile predicthaplo make If a segfault error occurs during the hp_predict_haplo stage, this is not a characteristic of HAPHPIPE but rather that of PredictHaplo. Sometimes, we have luck if we just rerun the code again or move to an interactive CPU node. We are unsure what causes this error, and we only see it between the local and global reconstruction phases in PredictHaplo. Quick start 1. Activate haphpipe Make sure you have conda running. For students at GW using Colonial One, you need to load the miniconda3 module like such prior to activating the haphpipe conda environemnt: module load miniconda3 . conda activate haphpipe 2. Test that it is loaded correctly haphpipe -h should produce: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data Windows Users HAPHPIPE is only available for Mac OSX or Linux platforms. We suggest the following options for running HAPHPIPE on a Windows machine: 1. Run HAPHPIPE on your institution's HPC cluster, if available. 2. Utilize the Windows Subsystem for Linux . 3. Run Linux in a virtual machine via VirtualBox","title":"Installation"},{"location":"install/#haphpipe-installation-instructions","text":"HAPHIPE depends on more than a dozen different programs, each of which may itself depend on other programs and libraries. Installing everything separately would be a nightmare, so you should use the package manager \"Bioconda\" to install everything. Bioconda is a popular package manager in the bioinformatics world. See the Helpful Resources section for more information and resources for Bioconda. Here, we will describe where to get Bioconda and how to install it, then how to use Bioconda to install the necessary programs for HAPHPIPE. We will also detail the acquisition and installation of one program, GTAK, that is not handled by Bioconda, and finally the acquisition and installation of HAPHPIPE itself. Here, we describe the procedure for installing HAPHPIPE using the package manager Bioconda (Gr\u00fcning et al. 2018) on the command line. If you are unfamiliar with Bioconda, please see for installation and channel setup. HAPHPIPE is available here and is written in Python 3.7.2 coding language. The installation process begins with the creation of a conda environment that installs the necessary dependencies required by HAPHPIPE. Once the conda environment has been created, it can be activated for use with the command conda activate haphpipe. Due to license restrictions, Bioconda cannot distribute and install GATK (McKenna et al. 2010; Van der Auwera et al. 2013; Poplin et al. 2018) directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute (link) . You can then install HAPHPIPE using the single command pip install git+git://github.com/gwcbi/haphpipe.git , which pulls the repository from Github. 1. Install conda Download the conda package: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh 2. Set up conda channels These need to be put in as a command in the order they come, as this sets the priority for where packages are pulled from. Therefore, in this order, conda-forge is top priority and explored first when downloading a program. conda config --add channels R conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge 3. Create a conda environment with the following dependencies conda create -n haphpipe \\ python=3.7 \\ future \\ pyyaml \\ biopython \\ seqtk \\ bowtie2 \\ bwa \\ flash \\ freebayes \\ mummer \\ picard \\ trimmomatic \\ samtools=1.9 \\ gatk=3.8 \\ spades \\ blast \\ sierrapy 4. Activate the environment conda activate haphpipe 5. Install GATK Due to license restrictions, bioconda cannot distribute and install GATK directly. To fully install GATK, you must download a licensed copy of GATK (version 3.8-0) from the Broad Institute: https://software.broadinstitute.org/gatk/download/archive . Register the package using gatk3-register: gatk3-register /path/to/GenomeAnalysisTK-3.8-0-ge9d806836.tar.bz2 This will copy GATK into your conda environment. Alternatively, GATK may be installed directly on the command line with the following commands: mkdir -p /path/to/gatk_dir wget -O - 'https://software.broadinstitute.org/gatk/download/auth?package=GATK-archive version=3.6-0-g89b7209' | tar -xjvC /path/to/gatk_dir gatk3-register /path/to/gatk_dir/GenomeAnalysisTK.jar NOTE: HAPHPIPE was developed and tested using GATK 3.8. 6. Install HAPHPIPE pip install git+git://github.com/gwcbi/haphpipe.git Upon completion of the installation, you can test it to ensure the repository has been installed completely and correctly by running haphpipe -h (in quick start). Once HAPHPIPE is installed and performing correctly, there is no need to install it again; simply activate the conda environment when needed by executing conda activate haphpipe . If a new version is released in the future, HAPHPIPE can be updated by running the command line pip install --upgrade git+git://github.com/gwcbi/haphpipe.git . At any point, the -h option that follows any HAPHPIPE stage will output a help message that provides a description of the stage and the desired input(s) and output(s).","title":"HAPHPIPE Installation Instructions"},{"location":"install/#predicthaplo-installation-instructions","text":"Users are required to download PredictHaplo on their own computing system prior to running any of the haplotype stages ( hp_predict_haplo and hp_ph_parser ). Here is how the GW CBI team installed PredictHaplo onto our HPC, which has a slurm scheduling system and uses Lua module files. We cannot help with the installation of this software, but have provided the code that we used here to install PredictHaplo onto our system. Please see their website for contact information if needed. This module loads predicthaplo onto GWU's HPC - Colonial One. See https://bmda.dmi.unibas.ch/software.html cd /path/to/modules/predicthaplo # use gcc 4.9.4, add blas and lapack to library path module load gcc/4.9.4 module load blas/gcc/64 module load lapack/gcc/64 # download source cd archive wget https://bmda.dmi.unibas.ch/software/PredictHaplo-Paired-0.4.tgz cd .. # unzip source and change directory name tar xfvz archive/PredictHaplo-Paired-0.4.tgz mv PredictHaplo-Paired-0.4 0.4 cd 0.4 # install scythestat tar xfvz scythestat-1.0.3.tar.gz cd scythestat-1.0.3 ./configure --prefix=/path/to/modules/predicthaplo/0.4/NEWSCYTHE make install cd .. # compile predicthaplo make If a segfault error occurs during the hp_predict_haplo stage, this is not a characteristic of HAPHPIPE but rather that of PredictHaplo. Sometimes, we have luck if we just rerun the code again or move to an interactive CPU node. We are unsure what causes this error, and we only see it between the local and global reconstruction phases in PredictHaplo.","title":"PredictHaplo Installation Instructions"},{"location":"install/#quick-start","text":"1. Activate haphpipe Make sure you have conda running. For students at GW using Colonial One, you need to load the miniconda3 module like such prior to activating the haphpipe conda environemnt: module load miniconda3 . conda activate haphpipe 2. Test that it is loaded correctly haphpipe -h should produce: Program: haphpipe (haplotype and phylodynamics pipeline) Version: 0.8.1 Commands: -- Reads sample_reads subsample reads using seqtk trim_reads trim reads using Trimmomatic join_reads join reads using FLASh ec_reads error correct reads using SPAdes -- Assemble assemble_denovo assemble reads denovo assemble_amplicons assemble contigs to amplicon regions assemble_scaffold assemble contigs to genome align_reads align reads to reference call_variants call variants vcf_to_consensus create consensus sequence from VCF refine_assembly iterative refinement: align - variants - consensus finalize_assembly finalize consensus sequence -- Haplotype predict_haplo assemble haplotypes with PredictHaplo ph_parser parse output from PredictHaplo. -- Annotate pairwise_align align consensus to an annotated reference extract_pairwise extract sequence regions from pairwise alignment annotate_from_ref annotate consensus from reference annotation -- Miscellaneous demo setup demo directory and test data","title":"Quick start"},{"location":"install/#windows-users","text":"HAPHPIPE is only available for Mac OSX or Linux platforms. We suggest the following options for running HAPHPIPE on a Windows machine: 1. Run HAPHPIPE on your institution's HPC cluster, if available. 2. Utilize the Windows Subsystem for Linux . 3. Run Linux in a virtual machine via VirtualBox","title":"Windows Users"},{"location":"modules/","text":"hp_reads Stages to manipulate reads. Use -h after any command for a list of options. sample_reads Subsample reads using seqtk ( seqtk documentation ). Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Sample Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] probability of being sampled, so the number of sampled reads is not precisely [frac * number of reads]. --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False. trim_reads Trim reads using Trimmomatic ( Trimmomatic documentation ). Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Trimmomatic Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). join_reads Join reads using FLASH ( FLASH documentation ). Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). FLASH Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). ec_reads Error correct reads using spades ( Spades documentation ). Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False. hp_assemble Stages to assemble consensus sequence(s). Use -h after any command for a list of options. assemble_denovo Assemble reads using denovo assembly. Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Assembly Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). assemble_amplicons Assemble contigs using reference and amplicon regions. Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). assemble_scaffold Scaffold contigs using reference sequence. Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Scaffold Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). align_reads Align reads to reference. Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa. Reference fasta file. --outdir Output directory (default: current directory). Alignment Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). call_variants Call variants. Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Variant Calling Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). vcf_to_consensus Create consensus sequence from VCF. Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Variant Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. refine_assembly Three step assembly refinement: align reads, call variants, and update reference. Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa. Reference fasta file. --outdir Output directory (default: False). Refinement Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). finalize_assembly Finalize consensus sequence, align all reads to consensus, and call variants in dataset. Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Consensus Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). hp_annotate Stages to annotate consensus sequence(s). Use -h after any command for a list of options. pairwise_align Align amplicons to reference. Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False). extract_pairwise Extract sequence regions from pairwise alignment. Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False). hp_annotate_from_ref Extract sequence regions from pairwise alignment. Output files: Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --ref_gtf GTF format file containing amplicon regions. --outfile Output file (default: stdout). Settings: Option Description --debug Print commands but do not run (default: False).","title":"Modules"},{"location":"modules/#hp_reads","text":"Stages to manipulate reads. Use -h after any command for a list of options.","title":"hp_reads"},{"location":"modules/#sample_reads","text":"Subsample reads using seqtk ( seqtk documentation ). Output files: sample_1.fastq sample_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Sample Options: Option Description --nreads Number of reads to sample. If greater than the number of reads in file, all reads will be sampled. --frac Fraction of reads to sample, between 0 and 1. Each read has [frac] probability of being sampled, so the number of sampled reads is not precisely [frac * number of reads]. --seed Seed for random number generator. Settings: Option Description --quiet Do not write output to console (silence stdout and stderr), default is False. --logfile Append console output to this file. --debug Print commands but do not run, default is False.","title":"sample_reads"},{"location":"modules/#trim_reads","text":"Trim reads using Trimmomatic ( Trimmomatic documentation ). Output files: trimmed_1.fastq trimmed_2.fastq trimmed_U.fastq trimmomatic_summary.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Trimmomatic Options: Option Description --adapter_file Adapter file. --trimmers Trim commands for trimmomatic (default: ['LEADING:3', 'TRAILING:3', 'SLIDINGWINDOW:4:15', 'MINLEN:36']). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"trim_reads"},{"location":"modules/#join_reads","text":"Join reads using FLASH ( FLASH documentation ). Output files: joined.fastq notjoined_1.fastq notjoined_2.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --outdir Output directory (default: current directory). FLASH Settings: Option Description --min_overlap The minimum required overlap length between two reads to provide a confident overlap (default: 10). --max_overlap Maximum overlap length expected in approximately 90% of read pairs, longer overlaps are penalized. --allow_outies Also try combining read pairs in the \"outie\" orientation (default: False). --encoding Quality score encoding. Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"join_reads"},{"location":"modules/#ec_reads","text":"Error correct reads using spades ( Spades documentation ). Output files: corrected_1.fastq corrected_2.fastq corrected_U.fastq Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run, default is False.","title":"ec_reads"},{"location":"modules/#hp_assemble","text":"Stages to assemble consensus sequence(s). Use -h after any command for a list of options.","title":"hp_assemble"},{"location":"modules/#assemble_denovo","text":"Assemble reads using denovo assembly. Output files: denovo_contigs.fna denovo_summary.txt Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --outdir Output directory (default: current directory). Assembly Options: Option Description --no_error_correction Do not perform error correction (default: False) --subsample Use a subsample of reads for assembly --seed Seed for random number generator (ignored if not subsampling) Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"assemble_denovo"},{"location":"modules/#assemble_amplicons","text":"Assemble contigs using reference and amplicon regions. Output files: amplicon_assembly.fna Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --ref_gtf GTF format file containing amplicon regions. --outdir Output directory (default: current directory). Scaffold Options: Option Description --sample_id Sample ID (default: sampleXX). --padding Bases to include outside reference annotation (default: 50). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"assemble_amplicons"},{"location":"modules/#assemble_scaffold","text":"Scaffold contigs using reference sequence. Output files: scaffold_aligned.fa scaffold_assembly.fa scaffold_imputed.fa scaffold_padded.out Input/Output Arguments: Option Description --contigs_fa Fasta file with assembled contigs. --ref_fa Fasta file with reference genome to scaffold against. --outdir Output directory (default: current directory). Scaffold Options: Option Description --seqname Name to append to scaffold sequence (default: sample01). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"assemble_scaffold"},{"location":"modules/#align_reads","text":"Align reads to reference. Output files: aligned.bam aligned.bt2.out Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa. Reference fasta file. --outdir Output directory (default: current directory). Alignment Options: Option Description --bt2_preset {very-fast, fast, sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). --no_realign Do not realign indels (default: False). --remove_duplicates Remove duplicates from final alignment. Otherwise duplicates are marked but not removed (default: False). --encoding {Phred+33,Phred+64} Quality score encoding. Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"align_reads"},{"location":"modules/#call_variants","text":"Call variants. Output files: variants.vcf.gz Input/Output Arguments: Option Description --aln_bam Alignment file. --ref_fa Reference fasta file. --outdir Output directory (default: False). Variant Calling Options: Option Description --emit_all Output calls for all site (default: False). --min_base_qual Minimum base quality required to consider a base for calling (default: 15). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"call_variants"},{"location":"modules/#vcf_to_consensus","text":"Create consensus sequence from VCF. Output files: consensus.fna Input/Output Arguments: Option Description --vcf VCF file (created with all sites). --outdir Output directory (default: False). --sampidx Index for sample if multi-sample VCF (default: 0). Variant Options: Option Description --min_DP Minimum depth to call site (default: 1). --major Allele fraction to make unambiguous call (default: 0.5). --minor Allele fraction to make ambiguous call (default: 0.2). Settings: Option Description --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file.","title":"vcf_to_consensus"},{"location":"modules/#refine_assembly","text":"Three step assembly refinement: align reads, call variants, and update reference. Output files: refined.fna Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa. Reference fasta file. --outdir Output directory (default: False). Refinement Options: Option Description --max_step Maximum number of refinement steps (default: 1). --subsample Use a subsample of reads for refinement. --seed Seed for random number generator (ignored if not subsampling). --sample_id Sample ID. Used as read group ID in BAM (default: sampleXX). Settings: Option Description --ncpu Number of CPUs to use (default: 1). --xmx Maximum heap size for Java VM, in GB (default: 32). --keep_tmp Additional options (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"refine_assembly"},{"location":"modules/#finalize_assembly","text":"Finalize consensus sequence, align all reads to consensus, and call variants in dataset. Output files: final.fna final.ban final.vcf.gz Input/Output Arguments: Option Description --fq1 Fastq file with read 1. --fq2 Fastq file with read 2. --fqU Fastq file with unpaired reads. --ref_fa Consensus fasta file. --outdir Output directory (default: current directory). Consensus Options: Option Description --bt2_preset {very-fast,fast,sensitive,very-sensitive,very-fast-local,fast-local,sensitive-local,very-sensitive-local} Bowtie2 preset to use (default: very-sensitive). --sample_id Sample ID (default: sampleXX). Settings: Option Description --ncpu Number of CPU to use (default: 1). --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"finalize_assembly"},{"location":"modules/#hp_annotate","text":"Stages to annotate consensus sequence(s). Use -h after any command for a list of options.","title":"hp_annotate"},{"location":"modules/#pairwise_align","text":"Align amplicons to reference. Output files: pairwise_aligned.json Input/Output Arguments: Option Description --amplicons_fa Fasta file with assembled amplicons. --ref_fa Reference fasta file. --ref_gtf GTF format file containing amplicon regions. Primary and alternate coding regions should be provided in the attribute field (for amino acid alignment). --outdir Output directory (default: False). Settings: Option Description --keep_tmp Keep temporary directory (default: False). --quiet Do not write output to console (silence stdout and stderr) (default: False). --logfile Append console output to this file. --debug Print commands but do not run (default: False).","title":"pairwise_align"},{"location":"modules/#extract_pairwise","text":"Extract sequence regions from pairwise alignment. Output files: stdout.fasta Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --outfile Output file (default: stdout). Options: Option Description --outfmt Format for output: nuc_fa, aln_fa, amp_gtf, ost, or prot_fa (default: nuc_fa). --refreg Reference region. String format is ref:start-stop. For example, the region string to extract pol when aligned to HXB2 is HIV_B.K03455.HXB2:2085-5096. Settings: Option Description --debug Print commands but do not run (default: False).","title":"extract_pairwise"},{"location":"modules/#hp_annotate_from_ref","text":"Extract sequence regions from pairwise alignment. Output files: Input/Output Arguments: Option Description --align_json JSON file describing alignment (output of pairwise_align stage). --ref_gtf GTF format file containing amplicon regions. --outfile Output file (default: stdout). Settings: Option Description --debug Print commands but do not run (default: False).","title":"hp_annotate_from_ref"},{"location":"phylo/","text":"Phylo includes phylogenomics stages. multiple_align_ Align consensus sequences using MAFFT ( documentation ). Input can be a list of directories which contain final.fna files or a fasta file, or both (in which case the sequences in the FASTA file are combined with the final.fna files retreived before the alignment. Sequences will be separated by amplicons using a supplied GTF file before alignment (unless the --alignall option is specified). This module may also be used to separate files by amplicons (without aligning) by specifying the --fastaonly option. Alignments are by default outputted as FASTA files, although PHYLIP ( --phylipout ) or CLUSTAL ( --clustalout ) output options are also available. Many options from MAFFT are available in this module. Please refer to the MAFFT documentation above for information about these options. Usage: haphpipe multiple_align [MAFFT OPTIONS] [HAPHPIPE OPTIONS] --seqs FASTA --dir_list TXT --ref_gtf GTF [--outdir] (or): hp_multiple_align [MAFFT OPTIONS] [HAPHPIPE OPTIONS] --seqs FASTA --dir_list TXT --ref_gtf GTF [--outdir] Output files: alignment files in FASTA format (default), one per amplicon (or one alignment.fasta file if using --alignall option) Note: MAFFT stores intermediate files in a temporary directory located in /tmp. More information is available here . Input/Output Arguments: Option Description --seqs SEQS FASTA file with sequences to be aligned --dir_list DIR_LIST List of directories which include a final.fna file,one on each line --ref_gtf REF_GTF Reference GTF file --out_align OUT_ALIGN Name for alignment file --nuc Assume nucleotide (default: False) --amino Assume amino (default: False) --clustalout Clustal output format (default: False) --phylipout PHYLIP output format (default: False) --inputorder Output order same as input (default: False) --reorder Output order aligned (default: False) --treeout Guide tree is output to the input.tree file (default:False) --quiet_mafft Do not report progress (default: False) --outdir OUTDIR Output directory MAFFT Options: Option Description --algo ALGO Use different algorithm in command: linsi, ginsi, einsi, fftnsi, fftns, nwns, nwnsi --auto Automatically select algorithm (default: False) --sixmerpair Calculate distance based on shared 6mers, on by default (default: False) --globalpair Use Needleman-Wunsch algorithm (default: False) --localpair Use Smith-Waterman algorithm (default: False) --genafpair Use local algorithm with generalized affine gap cost (default: False) --fastapair Use FASTA for pairwise alignment (default: False) --weighti WEIGHTI Weighting factor for consistency term --retree RETREE Number of times to build guide tree --maxiterate MAXITERATE Number of cycles for iterative refinement --noscore Do not check alignment score in iterative alignment (default: False) --memsave Use Myers-Miller algorithm (default: False) --parttree Use fast tree-building method with 6mer distance (default: False) --dpparttree Use PartTree algorithm with distances based on DP (default: False) --fastaparttree Use PartTree algorithm with distances based on FASTA (default: False) --partsize PARTSIZE Number of partitions for PartTree --groupsize GROUPSIZE Max number of sequences for PartTree MAFFT Parameters: Option Description --lop LOP Gap opening penalty --lep LEP Offset value --lexp LEXP Gap extension penalty --LOP LOP Gap opening penalty to skip alignment --LEXP LEXP Gap extension penalty to skip alignment --bl BL BLOSUM matrix: 30, 45, 62, or 80 --jtt JTT JTT PAM number 0 --tm TM Transmembrane PAM number 0 --aamatrix AAMATRIX Path to user-defined AA scoring matrix --fmodel Incorporate AA/nuc composition info into scoring matrix (default: False) Options: Option Description --ncpu NCPU Number of CPU to use (default: 1) --quiet Do not write output to console (silence stdout and stderr) (default: False) --logfile LOGFILE Name for log file (output) --debug Print commands but do not run (default: False) --fastaonly Output fasta files separated by region but do not align (default: False) --alignall Do not separate files by region, align entire file (default: False) Example usage: haphpipe multiple_align --dir_list demo_sra_list.txt --ref_gtf HIV_B.K03455.HXB2.gtf --phylipout --logfile demo_multiple_align.log","title":"Phylo"},{"location":"phylo/#multiple_align_","text":"Align consensus sequences using MAFFT ( documentation ). Input can be a list of directories which contain final.fna files or a fasta file, or both (in which case the sequences in the FASTA file are combined with the final.fna files retreived before the alignment. Sequences will be separated by amplicons using a supplied GTF file before alignment (unless the --alignall option is specified). This module may also be used to separate files by amplicons (without aligning) by specifying the --fastaonly option. Alignments are by default outputted as FASTA files, although PHYLIP ( --phylipout ) or CLUSTAL ( --clustalout ) output options are also available. Many options from MAFFT are available in this module. Please refer to the MAFFT documentation above for information about these options. Usage: haphpipe multiple_align [MAFFT OPTIONS] [HAPHPIPE OPTIONS] --seqs FASTA --dir_list TXT --ref_gtf GTF [--outdir] (or): hp_multiple_align [MAFFT OPTIONS] [HAPHPIPE OPTIONS] --seqs FASTA --dir_list TXT --ref_gtf GTF [--outdir] Output files: alignment files in FASTA format (default), one per amplicon (or one alignment.fasta file if using --alignall option) Note: MAFFT stores intermediate files in a temporary directory located in /tmp. More information is available here . Input/Output Arguments: Option Description --seqs SEQS FASTA file with sequences to be aligned --dir_list DIR_LIST List of directories which include a final.fna file,one on each line --ref_gtf REF_GTF Reference GTF file --out_align OUT_ALIGN Name for alignment file --nuc Assume nucleotide (default: False) --amino Assume amino (default: False) --clustalout Clustal output format (default: False) --phylipout PHYLIP output format (default: False) --inputorder Output order same as input (default: False) --reorder Output order aligned (default: False) --treeout Guide tree is output to the input.tree file (default:False) --quiet_mafft Do not report progress (default: False) --outdir OUTDIR Output directory MAFFT Options: Option Description --algo ALGO Use different algorithm in command: linsi, ginsi, einsi, fftnsi, fftns, nwns, nwnsi --auto Automatically select algorithm (default: False) --sixmerpair Calculate distance based on shared 6mers, on by default (default: False) --globalpair Use Needleman-Wunsch algorithm (default: False) --localpair Use Smith-Waterman algorithm (default: False) --genafpair Use local algorithm with generalized affine gap cost (default: False) --fastapair Use FASTA for pairwise alignment (default: False) --weighti WEIGHTI Weighting factor for consistency term --retree RETREE Number of times to build guide tree --maxiterate MAXITERATE Number of cycles for iterative refinement --noscore Do not check alignment score in iterative alignment (default: False) --memsave Use Myers-Miller algorithm (default: False) --parttree Use fast tree-building method with 6mer distance (default: False) --dpparttree Use PartTree algorithm with distances based on DP (default: False) --fastaparttree Use PartTree algorithm with distances based on FASTA (default: False) --partsize PARTSIZE Number of partitions for PartTree --groupsize GROUPSIZE Max number of sequences for PartTree MAFFT Parameters: Option Description --lop LOP Gap opening penalty --lep LEP Offset value --lexp LEXP Gap extension penalty --LOP LOP Gap opening penalty to skip alignment --LEXP LEXP Gap extension penalty to skip alignment --bl BL BLOSUM matrix: 30, 45, 62, or 80 --jtt JTT JTT PAM number 0 --tm TM Transmembrane PAM number 0 --aamatrix AAMATRIX Path to user-defined AA scoring matrix --fmodel Incorporate AA/nuc composition info into scoring matrix (default: False) Options: Option Description --ncpu NCPU Number of CPU to use (default: 1) --quiet Do not write output to console (silence stdout and stderr) (default: False) --logfile LOGFILE Name for log file (output) --debug Print commands but do not run (default: False) --fastaonly Output fasta files separated by region but do not align (default: False) --alignall Do not separate files by region, align entire file (default: False) Example usage: haphpipe multiple_align --dir_list demo_sra_list.txt --ref_gtf HIV_B.K03455.HXB2.gtf --phylipout --logfile demo_multiple_align.log","title":"multiple_align_"}]}